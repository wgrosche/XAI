{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14416540",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "\n",
    "Notebook dedicated to plotting the results of the explainer calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac5c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.integrate import odeint, solve_ivp\n",
    "from scipy.fft import fft\n",
    "\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import mpl_interactions.ipyplot as iplt\n",
    "sns.set_theme(context='notebook', style='darkgrid', palette='deep', font='sans-serif', font_scale=1, color_codes=True, rc=None)\n",
    "\n",
    "# Machine Learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow import keras\n",
    "\n",
    "import shap as shap\n",
    "try:\n",
    "    import lime\n",
    "    import lime.lime_tabular    \n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for reproducibility of this notebook:\n",
    "rng = np.random.RandomState(42)\n",
    "#tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e2b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "\n",
    "Settings=[\"Base\", \"Random\", \"Energy\",\"Gamma\"]\n",
    "Model_types=[\"True\", \"Complex\", \"Simple\"]\n",
    "Param_array = [{'alpha' : -1.0, 'beta' : 1.0, 'gamma' : 0.37, 'delta' : 0.3, 'omega' : 1.2}, \n",
    "                  {'alpha' : -1.0, 'beta' : 1.0, 'gamma' : 0.37, 'delta' : 1.0, 'omega' : 1.2},\n",
    "                  {'alpha' : 1.0, 'beta' : 1.0, 'gamma' : 0.37, 'delta' : 0.3, 'omega' : 1.2}, \n",
    "                  {'alpha' : -1.0, 'beta' : -1.0, 'gamma' : 0.37, 'delta' : 0.3, 'omega' : 1.2},\n",
    "                  {'alpha' : -1.0, 'beta' : 1.0, 'gamma' : 0.37, 'delta' : 0.3, 'omega' : 0.1},\n",
    "                  {'alpha' : -1.0, 'beta' : 1.0, 'gamma' : 0.5, 'delta' : 0.3, 'omega' : 1.2}]\n",
    "\n",
    "\n",
    "i = 3\n",
    "k = 1\n",
    "\n",
    "plot_features = [r\"$x_0$\", r\"$v_0$\", r\"$t$\"]\n",
    "plot_labels = [r\"$x_t$\", r\"$v_t$\"]\n",
    "\n",
    "feature_setting = Settings[i]\n",
    "params = Param_array[k]\n",
    "\n",
    "plot_features.append(feature_setting)\n",
    "results_folder = \"Array_Submission_8/\"\n",
    "save = True\n",
    "save_suffix = \"_setting_\"+str(i)+\"_param_\"+str(k)\n",
    "\n",
    "\n",
    "if feature_setting == \"Base\":\n",
    "    from Array_Submission_8.BaseDuffing import Duffing\n",
    "elif feature_setting == \"Random\":\n",
    "    from Array_Submission_8.RandomDuffing import Duffing\n",
    "elif feature_setting == \"Energy\":\n",
    "    from Array_Submission_8.EnergyDuffing import Duffing\n",
    "elif feature_setting == \"Gamma\":\n",
    "    from Array_Submission_8.GammaDuffing import Duffing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb091da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Data…: 100%|██████████████████| 200/200 [02:15<00:00,  1.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "duffing = Duffing(parameters = params)\n",
    "eom = duffing.eom\n",
    "features = duffing.features\n",
    "labels = duffing.labels\n",
    "\n",
    "# generate some data to train the scaler\n",
    "\n",
    "end_time = 20 #100\n",
    "duffing.generate(200, samples = 50, end_time = end_time)\n",
    "duffing.scale_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1a47f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100    0.020202\n",
       "Name: gamma, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duffing.X_df.loc[100:100,:]['gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16e763af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ebd29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Gamma_True__-1.0_1.0_1.0_1.2\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Array_Submission_8/Results/explainer_dataframe_Gamma_True__-1.0_1.0_1.0_1.2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-52e0b0fec589>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0msuffix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_setting\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mduffing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtemp_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults_folder\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"Results/explainer_dataframe_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtemp_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mbig_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbig_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    702\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Array_Submission_8/Results/explainer_dataframe_Gamma_True__-1.0_1.0_1.0_1.2.csv'"
     ]
    }
   ],
   "source": [
    "big_df = pd.DataFrame()\n",
    "models = {}\n",
    "histories = {}\n",
    "for j in Model_types:\n",
    "    print(j)\n",
    "    suffix = feature_setting + \"_\" + j + \"_\" + duffing.suffix\n",
    "    print(suffix)\n",
    "    temp_df = pd.read_csv(results_folder+\"Results/explainer_dataframe_\"+suffix+\".csv\")\n",
    "    temp_df.insert(0, \"Model\", [j for i in range(temp_df.shape[0])])\n",
    "    big_df = big_df.append(temp_df)\n",
    "    if j == \"True\":\n",
    "        models[j] = duffing\n",
    "        histories[j] = None\n",
    "    elif j != \"True\":\n",
    "        models[j] = tf.keras.models.load_model(results_folder+\"Models/Model\"+suffix)\n",
    "        histories[j] = pickle.load(open(results_folder+'Models/TrainingHistory/'+suffix, \"rb\"))  \n",
    "        \n",
    "X = pd.DataFrame(duffing.scaler.inverse_transform(big_df[features]), columns = features)\n",
    "y = pd.DataFrame(duffing.predict(big_df[features]), columns = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee9a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1, 1, figsize=(8, 8), gridspec_kw=dict(width_ratios=[4]))\n",
    "\n",
    "x_potential = np.linspace(-2,2,100)\n",
    "v_potential = 0\n",
    "y_potential = (0.5*v_potential**2 + 0.5*params['alpha']*x_potential**2 +0.25*params['beta']*x_potential**4)\n",
    "\n",
    "sns.lineplot(x = x_potential, y=y_potential,ax=axs)\n",
    "\n",
    "axs.set_xlabel(r'Position $(x_0)$')\n",
    "axs.set_ylabel('Potential')\n",
    "axs.set_title(r\"$\\alpha$ = \"+str(params['alpha']) + r\", $\\beta$ = \"+str(params['beta']))\n",
    "axs.set(xlim=(-2, 2), ylim=(-2, 2))\n",
    "    \n",
    "f.suptitle(\"Potential Energy of the System\", fontsize = 16)\n",
    "f.tight_layout()\n",
    "\n",
    "if save == True:\n",
    "    f.savefig(\"Images/Potential/\"+save_suffix+\".svg\", dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadc48fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = duffing.X_df[features].iloc[np.sort(np.random.choice(duffing.X_df[features].shape[0], 500, replace =False))]\n",
    "y_pred = {\"True\" : pd.DataFrame(duffing.predict(big_df[features]), columns = duffing.labels)}\n",
    "model_plot = {\"True\" : pd.DataFrame(duffing.predict(choice), columns = duffing.labels)}\n",
    "plot_t = pd.DataFrame(duffing.scaler.inverse_transform(choice), columns = features)['t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87f814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = {\"Complex\" : \"blue\", \"Simple\" : \"green\"}\n",
    "f, axs = plt.subplots(1, 3, figsize=(12, 4), gridspec_kw=dict(width_ratios=[4,4,4]))\n",
    "\n",
    "x_potential = np.linspace(-2,2,100)\n",
    "\n",
    "v_potential = 0\n",
    "y_potential = (0.5*v_potential**2 + 0.5*params['alpha']*x_potential**2 +0.25*params['beta']*x_potential**4)\n",
    "\n",
    "\n",
    "\n",
    "sns.lineplot(x = x_potential, y=y_potential,ax=axs[0])\n",
    "\n",
    "axs[0].set_xlabel('Position')\n",
    "axs[0].set_ylabel('Potential')\n",
    "axs[0].set_title(\"Potential Energy of the System\", fontsize = 14)\n",
    "\n",
    "\n",
    "for model_ in [\"Complex\", \"Simple\"]:\n",
    "    suffix = feature_setting + \"_\" + model_ + \"_\" + duffing.suffix\n",
    "    model = models[model_]\n",
    "    history = histories[model_]\n",
    "    \n",
    "    y_pred[model_] = pd.DataFrame(model.predict(big_df[features]), columns = duffing.labels)\n",
    "    model_plot[model_] = pd.DataFrame(model.predict(choice), columns = duffing.labels)\n",
    "\n",
    "    # evaluate NN performance\n",
    "\n",
    "    \"\"\"\n",
    "    Evaluate Model\n",
    "    \"\"\"\n",
    "\n",
    "    # evaluate the fitting validation and training losses\n",
    "    loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    ## Make Prdictions on the Test Dataset\n",
    "    #y_pred = pd.DataFrame(model.predict(big_df[features]), columns=['xt','vt'])\n",
    "\n",
    "    pred_norm = np.linalg.norm(y_pred[model_][['xt','vt']].values,axis=1)\n",
    "    true_norm = np.linalg.norm(y_pred[\"True\"][['xt','vt']].values,axis=1)\n",
    "    hist_data = np.abs(pred_norm-true_norm)/np.abs(true_norm)\n",
    "    hist_data = pd.DataFrame(hist_data, columns=['norm'])\n",
    "\n",
    "    def Remove_Outlier_Indices(df):\n",
    "        Q1 = df.quantile(0.00)\n",
    "        Q3 = df.quantile(0.95)\n",
    "        IQR = Q3 - Q1\n",
    "        trueList = ~((df > (Q3 + 1.5 * IQR)))\n",
    "        #trueList = ~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR)))\n",
    "        return trueList\n",
    "\n",
    "    indices = Remove_Outlier_Indices(hist_data)\n",
    "    hist_data = hist_data[indices]\n",
    "    # Model Loss and Error\n",
    "\n",
    "    sns.lineplot(data = history, x = epochs, y='loss',ax=axs[1], label=model_+' loss')\n",
    "    sns.lineplot(data = history, x = epochs, y='val_loss',ax=axs[1], label=model_ +' val_loss')\n",
    "\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Model Loss')\n",
    "    axs[1].set_title(\"Model Loss by Epoch\", fontsize = 14)\n",
    "    axs[1].legend()\n",
    "\n",
    "\n",
    "    # Error Plot for ML Predictions\n",
    "    sns.histplot(data=hist_data, x = 'norm', kde=False, stat='probability', binwidth=0.1, ax=axs[2], label = model_, color = colours[model_])\n",
    "\n",
    "    axs[2].set(xlim=(0, 1), ylim=(0, 0.4))\n",
    "    axs[2].set_xlabel('Error')\n",
    "    axs[2].set_ylabel('Probability')\n",
    "    axs[2].set_title(r\"Error Plot $(\\frac{||y_{pred}-y_{true}||}{||y_{true}||})$\", fontsize = 14)\n",
    "    axs[2].legend()\n",
    "\n",
    "f.tight_layout()\n",
    "\n",
    "if save == True:\n",
    "    f.savefig(\"Images/Performance/\"+save_suffix+\".svg\", dpi='figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9e12c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions Plot ML Model\n",
    "f, axs = plt.subplots(1, 3, figsize=(15, 5), gridspec_kw=dict(width_ratios=[4,4,4]))\n",
    "markers = {\"True\" : 'x', \"Complex\" : '.', \"Simple\" : '^'}\n",
    "for model_ in Model_types:\n",
    "    # phase space plot\n",
    "    sns.scatterplot(data = model_plot[model_].iloc[:200,:], x = 'xt', y='vt',ax=axs[0], label=model_,\n",
    "                marker=markers[model_], linewidth = 1, edgecolor = None)\n",
    "    # xt against time\n",
    "    sns.scatterplot(data = model_plot[model_].iloc[:200,:], x = plot_t[:200], y='xt',ax=axs[1],label=model_,\n",
    "                marker=markers[model_], linewidth = 1, edgecolor = None)\n",
    "    # vt against time\n",
    "    sns.scatterplot(data = model_plot[model_].iloc[:200,:], x = plot_t, y='vt',ax=axs[2],label=model_,\n",
    "                marker=markers[model_], linewidth = 1, edgecolor = None)\n",
    "    \n",
    "axs[0].set(xlim=(-2, 2), ylim=(-2, 2))\n",
    "axs[0].set_xlabel('x')\n",
    "axs[0].set_ylabel('v')\n",
    "axs[0].set_title(\"Phase Space Plot\")\n",
    "axs[0].legend(loc = 4)\n",
    "\n",
    "axs[1].set(xlim=(-1, 20), ylim=(-2, 2))\n",
    "axs[1].set_xlabel('t')\n",
    "axs[1].set_ylabel('x(t)')\n",
    "axs[1].set_title(\"x(t)\")\n",
    "axs[1].legend(loc = 4)\n",
    "\n",
    "axs[2].set(xlim=(-1, 100), ylim=(-2, 2))\n",
    "axs[2].set_xlabel('t')\n",
    "axs[2].set_ylabel('v(t)')\n",
    "axs[2].set_title(\"v(t)\")\n",
    "axs[2].legend(loc = 4)\n",
    "\n",
    "f.suptitle(\"Model Predictions\", fontsize = 16)\n",
    "f.tight_layout()\n",
    "\n",
    "if save == True:\n",
    "    f.savefig(\"Images/Predictions/\"+save_suffix+\".svg\", dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6178000",
   "metadata": {},
   "outputs": [],
   "source": [
    "for models_ in big_df['Model'].unique():\n",
    "    plotting_df = big_df.where(big_df[\"explainer\"].isin([\"sampling\", \"kernel\"])).where(big_df[\"Model\"]==models_).dropna()\n",
    "    plotting_df[duffing.features] = pd.DataFrame(duffing.scaler.inverse_transform(big_df[duffing.features]), \n",
    "                                                 columns = features)\n",
    "    f, axs = plt.subplots(len(duffing.labels), len(duffing.features), figsize = (len(duffing.features)*4,len(duffing.labels)*4), \n",
    "                      gridspec_kw = dict(width_ratios = [4 for i in duffing.features]))\n",
    "    for i, feat_ in enumerate(duffing.features):\n",
    "        for j, label_ in enumerate(duffing.labels):\n",
    "            sns.scatterplot(x=feat_, y=label_+\"_\"+feat_, data=plotting_df, ax=axs[j,i], \n",
    "                            linewidth = .1, hue = \"explainer\", style = \"explainer\", edgecolor=\"none\")\n",
    "            axs[j,i].set_title(plot_features[i]+\":\"+plot_labels[j])\n",
    "            axs[j,i].set_xlabel(plot_features[i])\n",
    "            axs[j,i].set_ylabel('Feature Contribution')\n",
    "    f.suptitle(r\"Individual Feature Contributions to $x_t$ and $v_t$ in the \" + models_ + \" Model\", fontsize = 16)\n",
    "\n",
    "    f.tight_layout()\n",
    "    if save == True:\n",
    "        f.savefig(\"Images/Individual/\"+models_+\"_\"+save_suffix+\".svg\", dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1782e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for models_ in big_df['Model'].unique():\n",
    "    plotting_df = big_df.where(big_df[\"explainer\"] == \"lime\").where(big_df[\"Model\"]==models_).dropna()\n",
    "    plotting_df[duffing.features] = pd.DataFrame(duffing.scaler.inverse_transform(big_df[duffing.features]), \n",
    "                                                 columns = features)\n",
    "    f, axs = plt.subplots(len(duffing.labels), len(duffing.features), figsize = (len(duffing.features)*4,len(duffing.labels)*4), \n",
    "                      gridspec_kw = dict(width_ratios = [4 for i in duffing.features]))\n",
    "    for i, feat_ in enumerate(duffing.features):\n",
    "        for j, label_ in enumerate(duffing.labels):\n",
    "            sns.scatterplot(x=feat_, y=label_+\"_\"+feat_, data=plotting_df, ax=axs[j,i], \n",
    "                            linewidth = .1, hue = \"explainer\", style = \"explainer\", edgecolor=\"none\")\n",
    "            axs[j,i].set_title(plot_features[i]+\":\"+plot_labels[j])\n",
    "            axs[j,i].set_xlabel('Index')\n",
    "            axs[j,i].set_ylabel('Feature Contribution')\n",
    "    f.suptitle(r\"Individual Feature Contributions to $x_t$ and $v_t$ in the \" + models_ + \" Model\", fontsize = 16)\n",
    "\n",
    "    f.tight_layout()\n",
    "    if save == True:\n",
    "        f.savefig(\"Images/Individual/WithLime\"+models_+\"_\"+save_suffix+\".svg\", dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d8bf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Data to Long Form to enable plotting with sns barplot\n",
    "for model_ in Model_types:\n",
    "    \n",
    "    plot_cols = [label_+\"_\"+feat_ for label_ in duffing.labels for feat_ in duffing.features]\n",
    "    plot_cols.append(\"explainer\")\n",
    "    model_df = big_df.where(big_df['Model'] == model_).dropna()\n",
    "    agg_df = model_df[plot_cols].copy().set_index('explainer')\n",
    "    temp_df = pd.DataFrame()\n",
    "    agg_df_2 = pd.DataFrame()\n",
    "    for j, col in enumerate(agg_df.columns[:8]):\n",
    "        for expl in agg_df.index.unique():\n",
    "            temp_df['value'] = agg_df.loc[expl][col].values\n",
    "            temp_df['feature'] = col\n",
    "            temp_df['explainer'] = expl\n",
    "            agg_df_2 = agg_df_2.append(temp_df)\n",
    "\n",
    "    agg_df_3 = agg_df_2.where(agg_df_2[\"explainer\"].isin([\"kernel\", \"sampling\"])).dropna()\n",
    "    for i, feat_ in enumerate(duffing.features):\n",
    "        for j, label_ in enumerate(duffing.labels):\n",
    "            agg_df_3 = agg_df_3.replace(label_+\"_\"+feat_, plot_features[i] +\":\" +plot_labels[j])\n",
    "            \n",
    "    # aggregated feature importance\n",
    "\n",
    "    # Aggregated\n",
    "\n",
    "    f, axs = plt.subplots(1, 2, figsize = (16,8), gridspec_kw = dict(width_ratios = [4,4]))\n",
    "\n",
    "\n",
    "    sns.barplot(data=agg_df_3, x = 'feature', y = np.abs(agg_df_3['value']), hue = 'explainer', ax = axs[0], ci = 95, capsize=.2)\n",
    "\n",
    "    axs[0].set_title(r\"Aggregate Feature Contributions in the \" + model_ + \" Model\", fontsize = 14)\n",
    "    axs[0].set_xlabel('Feature')\n",
    "    axs[0].set_ylabel('Feature Contribution')\n",
    "\n",
    "    sns.boxplot(data=agg_df_3, x = 'feature', y = 'value', ax = axs[1], hue = 'explainer')\n",
    "    axs[1].set_title(r\"All Feature Contributions in the \" + model_ + \" Model\", fontsize = 14)\n",
    "    axs[1].set_xlabel('Feature')\n",
    "    axs[1].set_ylabel('Feature Contribution')\n",
    "\n",
    "\n",
    "    f.tight_layout()\n",
    "\n",
    "    if save == True:\n",
    "        f.savefig(\"Images/Aggregate/\"+models_+\"_\"+save_suffix+\".svg\", dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f13e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Data to Long Form to enable plotting with sns barplot\n",
    "for model_ in Model_types:\n",
    "    \n",
    "    plot_cols = [label_+\"_\"+feat_ for label_ in duffing.labels for feat_ in duffing.features]\n",
    "    plot_cols.append(\"explainer\")\n",
    "    model_df = big_df.where(big_df['Model'] == model_).dropna()\n",
    "    agg_df = model_df[plot_cols].copy().set_index('explainer')\n",
    "    temp_df = pd.DataFrame()\n",
    "    agg_df_2 = pd.DataFrame()\n",
    "    for j, col in enumerate(agg_df.columns[:8]):\n",
    "        for expl in agg_df.index.unique():\n",
    "            temp_df['value'] = agg_df.loc[expl][col].values\n",
    "            temp_df['feature'] = col\n",
    "            temp_df['explainer'] = expl\n",
    "            agg_df_2 = agg_df_2.append(temp_df)\n",
    "\n",
    "    agg_df_3 = agg_df_2.where(agg_df_2[\"explainer\"].isin([\"kernel\", \"sampling\", \"lime\"])).dropna()\n",
    "    for i, feat_ in enumerate(duffing.features):\n",
    "        for j, label_ in enumerate(duffing.labels):\n",
    "            agg_df_3 = agg_df_3.replace(label_+\"_\"+feat_, plot_features[i] +\":\" +plot_labels[j])\n",
    "            \n",
    "    # aggregated feature importance\n",
    "\n",
    "    # Aggregated\n",
    "\n",
    "    f, axs = plt.subplots(1, 2, figsize = (16,8), gridspec_kw = dict(width_ratios = [4,4]))\n",
    "\n",
    "\n",
    "    sns.barplot(data=agg_df_3, x = 'feature', y = np.abs(agg_df_3['value']), hue = 'explainer', ax = axs[0], ci = 95, capsize=.2)\n",
    "\n",
    "    axs[0].set_title(r\"Aggregate Feature Contributions in the \" + model_ + \" Model\", fontsize = 14)\n",
    "    axs[0].set_xlabel('Feature')\n",
    "    axs[0].set_ylabel('Feature Contribution')\n",
    "\n",
    "    sns.boxplot(data=agg_df_3, x = 'feature', y = 'value', ax = axs[1], hue = 'explainer')\n",
    "    axs[1].set_title(r\"All Feature Contributions in the \" + model_ + \" Model\", fontsize = 14)\n",
    "    axs[1].set_xlabel('Feature')\n",
    "    axs[1].set_ylabel('Feature Contribution')\n",
    "\n",
    "\n",
    "    f.tight_layout()\n",
    "\n",
    "    if save == True:\n",
    "        f.savefig(\"Images/Aggregate/Lime\"+models_+\"_\"+save_suffix+\".svg\", dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe42a426",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.where(big_df[\"Model\"]==\"True\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849cf737",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.where(big_df[\"Model\"]==\"Complex\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97777ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.where(big_df[\"Model\"]==\"Simple\").where(big_df[\"explainer\"]==\"kernel\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3837e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_limits = [(-0.1,0.1), (-0.1,0.1), (-50,50)]\n",
    "for models_ in big_df['Model'].unique():\n",
    "    plotting_df = (big_df.where(big_df[\"explainer\"] == \"numeric\").where(big_df[\"Model\"] == models_).dropna())\n",
    "    plotting_df[duffing.features] = pd.DataFrame(duffing.scaler.inverse_transform(big_df[duffing.features]), \n",
    "                                                 columns = features)\n",
    "    f, axs = plt.subplots(len(duffing.labels), len(duffing.features), figsize = (len(duffing.features)*4,len(duffing.labels)*4), \n",
    "                      gridspec_kw = dict(width_ratios = [4 for i in duffing.features]))\n",
    "    for i, feat_ in enumerate(duffing.features):\n",
    "        for j, label_ in enumerate(duffing.labels):\n",
    "            sns.scatterplot(x=feat_, y=label_+\"_\"+feat_, data=plotting_df, ax=axs[j,i], \n",
    "                            linewidth = 1, hue = \"explainer\", style = \"explainer\", edgecolor=\"none\", markers = 'x')\n",
    "            axs[j,i].set_title(plot_features[i]+\":\"+plot_labels[j])\n",
    "            axs[j,i].set_xlabel('Index')\n",
    "            axs[j,i].set_ylabel('Feature Contribution')\n",
    "    f.suptitle(r\"Individual Feature Contributions to $x_t$ and $v_t$ in the \" + models_ + \" Model\", fontsize = 16)\n",
    "\n",
    "    f.tight_layout()\n",
    "    #if save == True:\n",
    "     #   f.savefig(\"Images/Individual/WithLime\"+models_+\"_\"+save_suffix+\".svg\", dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Data to Long Form to enable plotting with sns barplot\n",
    "for model_ in Model_types:\n",
    "    \n",
    "    plot_cols = [label_+\"_\"+feat_ for label_ in duffing.labels for feat_ in duffing.features]\n",
    "    plot_cols.append(\"explainer\")\n",
    "    model_df = big_df.where(big_df['Model'] == model_).dropna()\n",
    "    agg_df = model_df[plot_cols].copy().set_index('explainer')\n",
    "    temp_df = pd.DataFrame()\n",
    "    agg_df_2 = pd.DataFrame()\n",
    "    for j, col in enumerate(agg_df.columns[:8]):\n",
    "        for expl in agg_df.index.unique():\n",
    "            temp_df['value'] = agg_df.loc[expl][col].values\n",
    "            temp_df['feature'] = col\n",
    "            temp_df['explainer'] = expl\n",
    "            agg_df_2 = agg_df_2.append(temp_df)\n",
    "\n",
    "    agg_df_3 = agg_df_2.where(agg_df_2[\"explainer\"].isin([\"numeric\"])).dropna()\n",
    "    for i, feat_ in enumerate(duffing.features):\n",
    "        for j, label_ in enumerate(duffing.labels):\n",
    "            agg_df_3 = agg_df_3.replace(label_+\"_\"+feat_, plot_features[i] +\":\" +plot_labels[j])\n",
    "            \n",
    "    # aggregated feature importance\n",
    "\n",
    "    # Aggregated\n",
    "\n",
    "    f, axs = plt.subplots(1, 2, figsize = (16,8), gridspec_kw = dict(width_ratios = [4,4]))\n",
    "\n",
    "\n",
    "    sns.barplot(data=agg_df_3, x = 'feature', y = np.abs(agg_df_3['value']), hue = 'explainer', ax = axs[0], ci = 95, capsize=.2)\n",
    "\n",
    "    axs[0].set_title(r\"Aggregate Feature Contributions in the \" + model_ + \" Model\", fontsize = 14)\n",
    "    axs[0].set_xlabel('Feature')\n",
    "    axs[0].set_ylabel('Feature Contribution')\n",
    "\n",
    "    sns.boxplot(data=agg_df_3, x = 'feature', y = 'value', ax = axs[1], hue = 'explainer')\n",
    "    axs[1].set_title(r\"All Feature Contributions in the \" + model_ + \" Model\", fontsize = 14)\n",
    "    axs[1].set_xlabel('Feature')\n",
    "    axs[1].set_ylabel('Feature Contribution')\n",
    "\n",
    "\n",
    "    f.tight_layout()\n",
    "\n",
    "    if save == True:\n",
    "        f.savefig(\"Images/Aggregate/Numeric\"+models_+\"_\"+save_suffix+\".svg\", dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9863d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_choice = big_df[duffing.features][:30]\n",
    "plot_choice_arr = pd.DataFrame()\n",
    "for time in np.linspace(0, 100, 100, endpoint=False):\n",
    "    plot_choice[\"t\"] = time\n",
    "    plot_choice[\"t\"] = duffing.scaler.transform(plot_choice)[:,2]\n",
    "    plot_choice_arr = plot_choice_arr.append(plot_choice)\n",
    "    \n",
    " # Enable Jupyter Notebook's intellisense\n",
    "%config IPCompleter.greedy=True\n",
    "%matplotlib inline\n",
    "\n",
    "%matplotlib notebook\n",
    "from ipywidgets import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt   \n",
    "  \n",
    "pred_plot_choice_arr = models[\"Complex\"].predict(plot_choice_arr)\n",
    "\n",
    "\n",
    "time = range(100)\n",
    "\n",
    "def f1(time = 0, num_samples = 1000):\n",
    "    return pred_plot_choice_arr[time*30:(time+1)*30,0]\n",
    "    \n",
    "def f2(rand, time = 0):\n",
    "    return pred_plot_choice_arr[time*30:(time+1)*30,1]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "controls = iplt.plot(f1, f2, 'x', time=time)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "ax.set_title(r\"Evolution of Datapoints in Phase Space\")\n",
    "ax.set_xlabel(r\"$x_t$\")\n",
    "ax.set_ylabel(r\"$v_t$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a41769",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plot_choice = big_df[duffing.features][:30]\n",
    "plot_choice_arr = pd.DataFrame()\n",
    "for time in np.linspace(0, 100, 100, endpoint=False):\n",
    "    plot_choice[\"t\"] = time\n",
    "    plot_choice[\"t\"] = duffing.scaler.transform(plot_choice)[:,2]\n",
    "    plot_choice_arr = plot_choice_arr.append(plot_choice)\n",
    "    \n",
    " # Enable Jupyter Notebook's intellisense\n",
    "%config IPCompleter.greedy=True\n",
    "%matplotlib inline\n",
    "\n",
    "%matplotlib notebook\n",
    "from ipywidgets import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt   \n",
    "  \n",
    "pred_plot_choice_arr = models[\"True\"].predict(plot_choice_arr)\n",
    "\n",
    "\n",
    "time = range(100)\n",
    "\n",
    "def f1(time = 0, num_samples = 1000):\n",
    "    return pred_plot_choice_arr[time*30:(time+1)*30,0]\n",
    "    \n",
    "def f2(rand, time = 0):\n",
    "    return pred_plot_choice_arr[time*30:(time+1)*30,1]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "controls = iplt.plot(f1, f2, 'x', time=time)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "ax.set_title(r\"Evolution of Datapoints in Phase Space\")\n",
    "ax.set_xlabel(r\"$x_t$\")\n",
    "ax.set_ylabel(r\"$v_t$\")\n",
    "\n",
    "def numeric_norm(dataframe):\n",
    "    data_copy = dataframe.copy()\n",
    "    X = dataframe[duffing.features]\n",
    "    scaled_df = pd.DataFrame(duffing.scaler.inverse_transform(X), columns = duffing.features)\n",
    "    y = pd.DataFrame(models[\"True\"].predict(X), columns = duffing.labels)\n",
    "    for i in duffing.labels:\n",
    "        y_vals = y[i]\n",
    "        y_mean = y[i].mean()\n",
    "        Omega = np.zeros_like(y_vals)\n",
    "        \n",
    "        for j in duffing.features:\n",
    "            Omega += np.array(dataframe[i+\"_\"+j]) * np.array(scaled_df[j])\n",
    "            \n",
    "        for j in duffing.features:\n",
    "            data_copy[i+\"_\"+j] = np.array(dataframe[i+\"_\"+j]) * np.array(y_vals) / Omega\n",
    "        \n",
    "    return data_copy\n",
    "    \n",
    "def scale_numeric(dataframe):\n",
    "    data_out = dataframe.copy()\n",
    "    max_val = np.max(big_df.where(big_df[\"explainer\"] != \"numeric\").dropna().loc[:,\"xt_x0\":\"vt_t\"].max())\n",
    "    scaler = MinMaxScaler((-max_val, max_val))\n",
    "    data_out.loc[:,\"xt_x0\":\"vt_t\"]=scaler.fit_transform(dataframe.loc[:,\"xt_x0\":\"vt_t\"])\n",
    "    return data_out    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d978d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = shap.sample(duffing.X_df[duffing.features], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1622f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3696a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61e7dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_explainer = shap.KernelExplainer(models[\"Simple\"], background)\n",
    "temp_vals = temp_explainer.shap_values(pd.DataFrame(duffing.scaler.transform(X[:100])), columns = duffing.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4e5e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plotting_df = duffing.vals_to_df(temp_vals, X[:100])\n",
    "plotting_df[duffing.features] = pd.DataFrame(duffing.scaler.inverse_transform(big_df[duffing.features]), \n",
    "                                             columns = features)\n",
    "f, axs = plt.subplots(len(duffing.labels), len(duffing.features), figsize = (len(duffing.features)*4,len(duffing.labels)*4), \n",
    "                  gridspec_kw = dict(width_ratios = [4 for i in duffing.features]))\n",
    "for i, feat_ in enumerate(duffing.features):\n",
    "    for j, label_ in enumerate(duffing.labels):\n",
    "        sns.scatterplot(x=feat_, y=label_+\"_\"+feat_, data=plotting_df, ax=axs[j,i], \n",
    "                        linewidth = .1, hue = \"explainer\", style = \"explainer\", edgecolor=\"none\")\n",
    "        axs[j,i].set_title(plot_features[i]+\":\"+plot_labels[j])\n",
    "        axs[j,i].set_xlabel('Index')\n",
    "        axs[j,i].set_ylabel('Feature Contribution')\n",
    "f.suptitle(r\"Individual Feature Contributions to $x_t$ and $v_t$ in the \" + models_ + \" Model\", fontsize = 16)\n",
    "\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3804a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
