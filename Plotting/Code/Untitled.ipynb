{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef905430",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-686249881da5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m#model_setting = str(os.environ[\"Model\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[0mmodel_setting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mfeature_setting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '-f'"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from scipy.integrate import odeint, solve_ivp\n",
    "from scipy.fft import fft\n",
    "\n",
    "\n",
    "import shap as shap\n",
    "try:\n",
    "    import lime\n",
    "    import lime.lime_tabular    \n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Machine Learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow import keras\n",
    "\n",
    "# for reproducibility of this notebook:\n",
    "rng = np.random.RandomState(42)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "#idx = int(os.environ[\"SLURM_ARRAY_TASK_ID\"])\n",
    "\n",
    "#feature_setting = str(os.environ[\"Setting\"])\n",
    "\n",
    "#model_setting = str(os.environ[\"Model\"])\n",
    "idx = int(sys.argv[1])\n",
    "model_setting = sys.argv[2]\n",
    "feature_setting = sys.argv[3]\n",
    "\n",
    "\"\"\"\n",
    "Define Parameter Configuration to Model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : float, linear stiffness\n",
    "    beta  : float, non linearity in the restoring force\n",
    "    gamma : float, amplitude of the periodic driving force\n",
    "    delta : float, amount of damping\n",
    "    omega : float, angular frequency of the periodic driving force\n",
    "\"\"\"   \n",
    "\n",
    "parameter_list = [{'alpha' : 1.0, 'beta' : 1.0, 'gamma' : 0.37, 'delta' : 0.3, 'omega' : 1.2}, \n",
    "                  {'alpha' : 1.0, 'beta' : -0.5, 'gamma' : 0.37, 'delta' : 0.3, 'omega' : 1.2},\n",
    "                  {'alpha' : 1.0, 'beta' : -0.5, 'gamma' : 0.37, 'delta' : 1.0, 'omega' : 1.2}, \n",
    "                  {'alpha' : 1.0, 'beta' : -0.5, 'gamma' : 0.5, 'delta' : 0.3, 'omega' : 1.2},\n",
    "                  {'alpha' : 1.0, 'beta' : -0.5, 'gamma' : 0.37, 'delta' : 0.0, 'omega' : 1.2},\n",
    "                  {'alpha' : -1.0, 'beta' : 1.0, 'gamma' : 0.37, 'delta' : 0.3, 'omega' : 1.2},\n",
    "                  {'alpha' : -1.0, 'beta' : 1.0, 'gamma' : 0.37, 'delta' : 1.0, 'omega' : 1.2}, \n",
    "                  {'alpha' : -1.0, 'beta' : 1.0, 'gamma' : 0.5, 'delta' : 0.3, 'omega' : 1.2},\n",
    "                  {'alpha' : -1.0, 'beta' : 1.0, 'gamma' : 0.0, 'delta' : 0.3, 'omega' : 0.0},\n",
    "                  {'alpha' : -1.0, 'beta' : -1.0, 'gamma' : 0.37, 'delta' : 0.3, 'omega' : 1.2},\n",
    "                  {'alpha' : 0.0, 'beta' : 0.0, 'gamma' : 0.37, 'delta' : 0.3, 'omega' : 1.2}]\n",
    "\n",
    "\n",
    "dict_param = parameter_list[idx]\n",
    "\n",
    "from OtherFunctions import *\n",
    "\n",
    "if feature_setting == \"Base\":\n",
    "    from  BaseDuffing import Duffing\n",
    "elif feature_setting == \"Random\":\n",
    "    from  RandomDuffing import Duffing\n",
    "elif feature_setting == \"Energy\":\n",
    "    from  EnergyDuffing import Duffing\n",
    "elif feature_setting == \"Gamma\":\n",
    "    from  GammaDuffing import Duffing\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    duffing = Duffing(parameters = dict_param)\n",
    "    eom = duffing.eom\n",
    "    suffix = feature_setting + \"_\" + model_setting + \"_\" + duffing.suffix\n",
    "\n",
    "    end_time = 100\n",
    "    duffing.generate(10, samples = 10, end_time = end_time)\n",
    "    duffing.scale_features()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(duffing.X_df[duffing.features], \n",
    "                                                        duffing.X_df[duffing.labels], test_size=0.1, random_state=42)\n",
    "    \n",
    "    X = X_test\n",
    "    y = y_test\n",
    "    \n",
    "    # Create a basic model instance\n",
    "    if model_setting == \"Complex\":\n",
    "        model = MLModel()\n",
    "    elif model_setting == \"Simple\":\n",
    "        model = SimpleModel()\n",
    "    elif model_setting == \"True\":\n",
    "        model = duffing\n",
    "        \n",
    "    \n",
    "    if (model_setting == \"Simple\") or (model_setting == \"Complex\"):\n",
    "        \"\"\"\n",
    "        Train Model\n",
    "        \"\"\"\n",
    "        callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=25),\n",
    "                     tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15)]\n",
    "\n",
    "\n",
    "        history=model.fit(X_train, y_train, steps_per_epoch=None, epochs=500, validation_split=0.2, \n",
    "                          batch_size=1024, shuffle=True, callbacks=callbacks, verbose=0)\n",
    "\n",
    "\n",
    "        model.save('Models/Model'+suffix)\n",
    "        with open('Models/TrainingHistory/'+suffix, 'wb') as file_pi:\n",
    "            pickle.dump(history.history, file_pi)\n",
    "    \n",
    "    def lime_x(X):\n",
    "        return model.predict(X)[:,0]\n",
    "    def lime_v(X):\n",
    "        return model.predict(X)[:,1]\n",
    "    \n",
    "\n",
    "    explainers = [\"kernel\", \"sampling\", \"lime\", \"numeric\"]\n",
    "    lime_models = [lime_x, lime_v]\n",
    "\n",
    "    background = shap.sample(X_test, 1)\n",
    "    choice = X.iloc[np.sort(np.random.choice(X_test.shape[0], 1, replace =False))]\n",
    "\n",
    "\n",
    "    big_df = pd.DataFrame()\n",
    "    for explainer in explainers:\n",
    "        print(explainer + model_)\n",
    "        if explainer == \"kernel\":\n",
    "            temp_explainer = shap.KernelExplainer(models[model_], background)\n",
    "            temp_vals = temp_explainer.shap_values(choice)\n",
    "        elif explainer == \"sampling\":\n",
    "            temp_explainer = shap.SamplingExplainer(models[model_], background)\n",
    "            temp_vals = temp_explainer.shap_values(choice)\n",
    "        elif explainer == \"lime\":\n",
    "            temp_explainer = MyLime(lime_models[model_], choice, mode='regression')\n",
    "            temp_vals = temp_explainer.attributions(choice)\n",
    "        elif explainer == \"numeric\":\n",
    "            temp_explainer = NumericExplainer(models[model_], duffing.features, duffing.labels, h = 0.001)\n",
    "            temp_vals = temp_explainer.feature_att(choice)\n",
    "        else:\n",
    "            print(\"not a valid explainer type\")\n",
    "        big_df = big_df.append(duffing.vals_to_df(temp_vals, choice, explainer = explainer, suffix = suffix))\n",
    "\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d0f936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
