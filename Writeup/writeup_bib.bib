% Encoding: UTF-8
@InProceedings{hugojairescalanteand2017design,
author = {, Hugo Jair Escalante and , Isabelle Guyon and , Sergio Escalera and , Julio Jacques and Madadi, Meysam and , Xavier Baró and Ayache, Stephane and Viegas, Evelyne and Güçlütürk, Yağmur and Güçlü, Umut and , Marcel A. J. van Gerven and , Rob van Lier},
title = {Design of an explainable machine learning challenge for video interviews},
booktitle = {Proceedings of International Joint Conference on Neural Networks (IJCNN), 2017},
year = {2017},
month = {July},
abstract = {This paper reviews and discusses research advances on “explainable machine learning” in computer vision. We focus on a particular area of the “Looking at People” (LAP) thematic domain: first impressions and personality analysis. Our aim is to make the computational intelligence and computer vision communities aware of the importance of developing explanatory mechanisms for computer-assisted decision making applications, such as automating recruitment. Judgments based on personality traits are being made routinely by human resource departments to evaluate the candidates' capacity of social insertion and their potential of career growth. However, inferring personality traits and, in general, the process by which we humans form a first impression of people, is highly subjective and may be biased. Previous studies have demonstrated that learning machines can learn to mimic human decisions. In this paper, we go one step further and formulate the problem of explaining the decisions of the models as a means of identifying what visual aspects are important, understanding how they relate to decisions suggested, and possibly gaining insight into undesirable negative biases. We design a new challenge on explainability of learning machines for first impressions analysis. We describe the setting, scenario, evaluation metrics and preliminary outcomes of the competition. To the best of our knowledge this is the first effort in terms of challenges for explainability in computer vision. In addition our challenge design comprises several other quantitative and qualitative elements of novelty, including a “coopetition” setting, which combines competition and collaboration.

&nbsp;},
publisher = {IEEE},
url = {https://www.microsoft.com/en-us/research/publication/design-of-an-explainable-machine-learning-challenge-for-video-interviews/},
edition = {Proceedings of International Joint Conference on Neural Networks (IJCNN), 2017},
}
@InProceedings{lime,
  author    = {Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
  booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining, San Francisco, CA, USA, August 13-17, 2016},
  title     = {"Why Should {I} Trust You?": Explaining the Predictions of Any Classifier},
  year      = {2016},
  pages     = {1135--1144},
}

@InCollection{NIPS2017_7062,
  author    = {Lundberg, Scott M and Lee, Su-In},
  booktitle = {Advances in Neural Information Processing Systems 30},
  publisher = {Curran Associates, Inc.},
  title     = {A Unified Approach to Interpreting Model Predictions},
  year      = {2017},
  editor    = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  pages     = {4765--4774},
  url       = {http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf},
}

@Comment{jabref-meta: databaseType:bibtex;}
