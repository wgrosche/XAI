{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0caa79b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# True Model\n",
    "from scipy.integrate import odeint\n",
    "from scipy.fft import fft\n",
    "\n",
    "# Machine Learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# Data Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Plotting Libraries\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import shap\n",
    "\n",
    "\n",
    "# My Modules\n",
    "from wilkeXAI.data_generator import DataGenerator\n",
    "import wilkeXAI.wilke_shap as fwg\n",
    "  \n",
    "# Set Seaborn Theme\n",
    "sns.set_theme(context='notebook', style='darkgrid', palette='deep', font='sans-serif', font_scale=1, color_codes=True, rc=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f82e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator():\n",
    "    def __init__(self, features = ['x0','v0','t','rand'], \n",
    "                 labels = ['xt','vt'], \n",
    "                 x_range=[-2,2], v_range = [-1,1]):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.x_range = x_range\n",
    "        self.v_range = v_range\n",
    "    \n",
    "    def generate(self, num_samples = int(1e3), delay=0, samples=500, end_time=100, \n",
    "                 params = {'alpha' : [-1],'beta' : [1], 'gamma' :[0.37], 'delta' : [1], 'omega' : [1.2]}):\n",
    "        \"\"\"\n",
    "            Generates training samples using scipy.integrate.odeint\n",
    "            to calculate the temporal evolution of a Duffing system.\n",
    "    \n",
    "            Samples randomly from x0 in [-2,2], v0 in [-1,1].\n",
    "    \n",
    "            For each set of initial conditions we generate a trajectory.\n",
    "            The trajectory is randomly sampled to generate training\n",
    "            pairs: X = (x0,v0,t), y = (xt,vt)\n",
    "    \n",
    "            Input\n",
    "            ----------\n",
    "            num_samples : int, number of training\n",
    "                            samples to be generated\n",
    "    \n",
    "            Returns\n",
    "            ----------\n",
    "            X : array((num_samples,3)), each entry in the array\n",
    "                is a training sample (x0,v0,t)\n",
    "            y : array((num_samples,2)), each entry in the array\n",
    "                is a target sample (xt,vt)\n",
    "        \"\"\"\n",
    "        #Initialise the output arrays\n",
    "        self.params = params\n",
    "        self.parameter_length = 1\n",
    "        for key in self.params:\n",
    "            self.parameter_length  *= len(self.params[key]) \n",
    "        self.X = np.empty((num_samples*self.parameter_length, (len(self.features)+len(params))))\n",
    "        self.y = np.empty((num_samples*self.parameter_length, len(self.labels)))\n",
    "        complete_feature_vec = self.features.copy()\n",
    "        for k in params:\n",
    "            complete_feature_vec.append(k)\n",
    "        #Define bounds of the sampling\n",
    "        x_min = self.x_range[0]\n",
    "        x_max = self.x_range[1]\n",
    "        v_min = self.v_range[0]\n",
    "        v_max = self.v_range[1]\n",
    "        #Define the t_range to draw from\n",
    "        t_range = np.linspace(0, end_time, samples, endpoint=False)\n",
    "        #Generate num_samples samples\n",
    "        for i in tqdm(range(num_samples), desc=\"Generating Data…\", ascii=False, ncols=75):\n",
    "            ticker = 0\n",
    "            #Generate random starting positions\n",
    "            x0 = (x_max - x_min) * np.random.random_sample() + x_min\n",
    "            v0 = (v_max - v_min) * np.random.random_sample() + v_min\n",
    "            for alpha in params['alpha']:\n",
    "                for beta in params['beta']:\n",
    "                    for gamma in params['gamma']:\n",
    "                        for delta in params['delta']:\n",
    "                            for omega in params['omega']:\n",
    "                                \n",
    "                                self.current_params = {'alpha' : alpha,'beta' : beta, 'delta' : delta, \n",
    "                                                       'gamma' :gamma, 'omega' : omega}\n",
    "                                #Generate a trajectory\n",
    "                                trajectory = odeint(self.eom, [x0,v0], t_range)\n",
    "                                t_ind = samples-10#np.random.randint(samples)\n",
    "                                self.X[i*self.parameter_length+ticker,:] = [x0, v0, t_range[t_ind], np.random.sample(), alpha, beta, gamma, delta, omega]\n",
    "                                self.y[i*self.parameter_length+ticker,:] = trajectory[t_ind,:]\n",
    "                                ticker +=1\n",
    "                                    \n",
    "                                    \n",
    "        \n",
    "        \n",
    "        self.X = pd.DataFrame(self.X, columns = complete_feature_vec)\n",
    "        self.y = pd.DataFrame(self.y, columns = self.labels)\n",
    "        return self.X, self.y\n",
    "\n",
    "\n",
    "    def save(self, suffix=None, filepath = \"Data/\"):\n",
    "        self.X.to_csv(filepath+\"X\"+suffix+\".csv\")\n",
    "        self.y.to_csv(filepath+\"y\"+suffix+\".csv\")\n",
    "        \n",
    "    def eom(self, u, t):\n",
    "        \"\"\"\n",
    "            Duffing Oscillator Equation of Motion\n",
    "    \n",
    "            ddx + delta * dx**2 + alpha * x + beta * x**3 = gamma * cos(omega * t)\n",
    "    \n",
    "            Input\n",
    "            ----------\n",
    "            u : vector of length 2, (x,v)\n",
    "                Position and Velocity at time t\n",
    "            t : float, the time t\n",
    "    \n",
    "            Parameters\n",
    "            ----------\n",
    "            alpha : float, linear stiffness\n",
    "            beta  : float, non linearity in the restoring force\n",
    "            gamma : float, amplitude of the periodic driving force\n",
    "            delta : float, amount of damping\n",
    "            omega : float, angular frequency of the periodic driving force\n",
    "    \n",
    "            Returns\n",
    "            ----------\n",
    "            [dx,ddx] : Tuple, Time derivatives of \n",
    "                        position and velocity at time t\n",
    "    \n",
    "        \"\"\"\n",
    "        x, dx = u[0], u[1]\n",
    "        ddx = (self.current_params['gamma'] * np.cos(self.current_params['omega'] * t) - \n",
    "               (self.current_params['delta'] * dx + self.current_params['alpha']*x + self.current_params['beta'] * x**3))\n",
    "    \n",
    "        return [dx,ddx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ca3cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Data…: 100%|█████████████| 10000/10000 [00:27<00:00, 365.90it/s]\n"
     ]
    }
   ],
   "source": [
    "data_parameters = {'alpha' : [-1],'beta' : [1], 'gamma' :[0], 'delta' : [1], 'omega' : [1.2]}\n",
    "generator = DataGenerator()\n",
    "\n",
    "X, y = generator.generate(num_samples=int(1e4), params = data_parameters, delay=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a28544e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>delta</th>\n",
       "      <th>omega</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alpha  beta  gamma  delta  omega\n",
       "0      -1.0   1.0    0.0    1.0    1.2\n",
       "1      -1.0   1.0    0.0    1.0    1.2\n",
       "2      -1.0   1.0    0.0    1.0    1.2\n",
       "3      -1.0   1.0    0.0    1.0    1.2\n",
       "4      -1.0   1.0    0.0    1.0    1.2\n",
       "...     ...   ...    ...    ...    ...\n",
       "9995   -1.0   1.0    0.0    1.0    1.2\n",
       "9996   -1.0   1.0    0.0    1.0    1.2\n",
       "9997   -1.0   1.0    0.0    1.0    1.2\n",
       "9998   -1.0   1.0    0.0    1.0    1.2\n",
       "9999   -1.0   1.0    0.0    1.0    1.2\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.loc[:,('alpha','beta','gamma','delta','omega')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "52429061",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrueModel():\n",
    "    \"\"\"\n",
    "    Class to represent the True Model of the Duffing oscillator.\n",
    "    Uses the scipy odeint integrator to perform time evolution.\n",
    "    \"\"\"\n",
    "    def __init__(self, scaler, X):\n",
    "        \"\"\"\n",
    "            Intialise Model\n",
    "\n",
    "            Inputs\n",
    "            --------\n",
    "            scaler : sklearn.preprocessing.Standardscaler object that has already been trained\n",
    "            X : pd.DataFrame with columns giving the features\n",
    "        \"\"\"\n",
    "        self.scaler = scaler\n",
    "        self.cols = X.columns\n",
    "        \n",
    "    def eom(self, u, t, params = {'alpha' : [-1],'beta' : [1], 'gamma' :[0.37], 'delta' : [1], 'omega' : [1.2]}):\n",
    "        \"\"\"\n",
    "            Equation of Motion for the Duffing Oscillator\n",
    "\n",
    "            Inputs\n",
    "            --------\n",
    "            u : vector of floats, x, v\n",
    "            t : float, time t\n",
    "\n",
    "        \"\"\"\n",
    "        x, dx = u[0], u[1]\n",
    "        ddx= self.gamma * np.cos(self.omega * t) - (self.delta * dx + self.alpha*x + self.beta * x**3)\n",
    "        return [dx,ddx]\n",
    "    \n",
    "    def predict(self, X, params = {'alpha' : [-1],'beta' : [1], 'gamma' :[0.37], 'delta' : [1], 'omega' : [1.2]}):\n",
    "        \"\"\"\n",
    "            Calculates the temporal evolution of [X['x0'], X['v0']] to time X['t'].\n",
    "\n",
    "            Inputs\n",
    "            --------\n",
    "            X : pandas DataFrame with at least columns x0,v0,t\n",
    "\n",
    "            Returns\n",
    "            --------\n",
    "            y : pandas.DataFrame with columns xt,vt\n",
    "        \"\"\"\n",
    "        eom = lambda u, t: self.eom(u, t, params = {'alpha' : X['alpha'],'beta' : [1], 'gamma' :[0.37], 'delta' : [1], 'omega' : [1.2]})\n",
    "        if type(X) == pd.core.frame.DataFrame:\n",
    "            X = pd.DataFrame(self.scaler.inverse_transform(X.values), columns=X.columns)\n",
    "        elif type(X) == np.ndarray:\n",
    "            X = pd.DataFrame(self.scaler.inverse_transform(X), columns=self.cols)\n",
    "        #X = pd.DataFrame(self.scaler.inverse_transform(X[:,:3]), columns=['x0','v0','t'])\n",
    "        y = np.ones((np.shape(X)[0], 2))\n",
    "        for i in range(0,np.shape(X)[0]):\n",
    "            t_range = np.linspace(0, X['t'].iloc[i], 500, endpoint=False)\n",
    "            y[i,:] = odeint(self.eom, [X['x0'].iloc[i],X['v0'].iloc[i]], t_range)[-1]\n",
    "        #y = pd.DataFrame(y, columns=['xt','vt'])    \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a383ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class wilke_explainer():\n",
    "    \"\"\"\n",
    "        Class to evaluate models and plot both the individual and aggregate \n",
    "        feature importance. Implements a method for shap and for lime.\n",
    "        Implements methods from the SHAP library, tailored for this notebook.\n",
    "    \"\"\"\n",
    "    def __init__(self, models, background_data, test_data, test_labels, suffix = None, data_tol=0.1, num_vals=100, \n",
    "                 explainer_type='shap', background_resolution=100, tolerance=0.1):\n",
    "        \"\"\"\n",
    "            Initialises the explainer objects for the various models.\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            models : dictionary of models that implement a predict function\n",
    "                that take a 2d numpy.array or pandas.DataFrame\n",
    "                \n",
    "            background_data : pandas.DataFrame with samples of training data,\n",
    "                used to create a masker for the explainer objects\n",
    "                \n",
    "            test_data : pandas.DataFrame with samples of test data,\n",
    "                used to choose samples on which to evaluate the explainers.\n",
    "                \n",
    "            test_labels : pandas.DataFrame with samples of test labels,\n",
    "                used to choose good samples on which to evaluate the explainers.\n",
    "\n",
    "            suffix : str, added to the saving filepath for the plots.\n",
    "                \n",
    "            data_tol : float, thickness of band in which data_points are considered \n",
    "                to be close to the mean value.\n",
    "                \n",
    "            num_vals : int, maximum number of values on which the explainers are\n",
    "                evaluated.\n",
    "                \n",
    "            explainer_type : str, 'shap' or 'lime', decides which explainer is being\n",
    "                implemented: shap.KernelExplainer or shap.LimeTabular.\n",
    "                \n",
    "            background_resolution : int, number of samples of the background_data to\n",
    "                be used to create the masker for the explainers.\n",
    "                \n",
    "            tolerance : float, determines how close a model prediction must be to the\n",
    "                true value for it to be considered a good estimate.\n",
    "\n",
    "        \"\"\"\n",
    "        self.num_vals = num_vals\n",
    "        self.tol = data_tol\n",
    "        self.models = models\n",
    "        self.background_data = background_data\n",
    "        self.test_data = test_data\n",
    "        self.test_labels = test_labels\n",
    "        self.tolerance = tolerance\n",
    "        self.explainers = {}\n",
    "        self.suffix = suffix\n",
    "        self.background = shap.sample(self.background_data, background_resolution)\n",
    "        self.explainer_type = explainer_type\n",
    "        if explainer_type=='shap':\n",
    "             for mod in models:\n",
    "                self.explainers[mod] = shap.KernelExplainer((models[mod]).predict, self.background)\n",
    "                \n",
    "        elif explainer_type=='lime':\n",
    "             for mod in models:\n",
    "                self.explainers[mod] = shap.other.LimeTabular((models[mod]).predict, \n",
    "                                                                     self.background, mode=\"regression\")\n",
    "        elif explainer_type=='analytic':\n",
    "            for mod in models:\n",
    "                self.explainers[mod] = AnalyticExplainer(models[mod].predict, test_data.columns, test_labels.columns)\n",
    "    \n",
    "    def choose_data(self, feature, i):\n",
    "        \"\"\"\n",
    "            Chooses the data points on which the explainer will be evaluated for\n",
    "            a given feature. First, removes any points where the prediction is\n",
    "            further than tolerance from the true value. Second, takes values in\n",
    "            a band of thickness tol around 0 for all features not currently being\n",
    "            evaluated on. Third, chooses a random subset of length num_vals of \n",
    "            these values. This function should never be called outside of this class.\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            i : int, index of the feature being explained\n",
    "            feature : str, the feature being explained\n",
    "            num_features : the total number of features\n",
    "            \n",
    "            Returns\n",
    "            ----------\n",
    "            data_arr : pandas.DataFrame, array of the chosen values.\n",
    "        \"\"\"\n",
    "        vals = np.abs(np.linalg.norm((self.models['ml']).predict(self.test_data), axis=1) - \n",
    "                      np.linalg.norm(self.test_labels, axis=1))\n",
    "        data_arr = self.test_data.iloc[np.where(vals < self.tolerance)]\n",
    "        where__ = np.ones_like(data_arr[feature].values, dtype=bool)\n",
    "        \n",
    "        for j in range(1,3):\n",
    "            where__ = np.multiply(where__, np.abs(data_arr.values[:,(i + j)%3])<self.tol)\n",
    "        data_arr = data_arr.iloc[where__]\n",
    "        data_arr = data_arr.iloc[np.sort(\n",
    "            np.random.choice(data_arr.shape[0], np.min([self.num_vals, data_arr.shape[0]]), replace=False))]\n",
    "        return data_arr \n",
    "        \n",
    "    def eval_explainer(self):\n",
    "        \"\"\"\n",
    "            Evaluates the explainers on data chosen by the choose_data function.\n",
    "            \n",
    "            Returns\n",
    "            ---------\n",
    "            feature_attributions : pandas.DataFrame, array of the feature attributions\n",
    "                with a multiindex (index, feature, contribution, model)\n",
    "        \"\"\"\n",
    "        first_run = True\n",
    "        for i, __feature in enumerate(self.test_data.columns):\n",
    "            if __feature in ['x0','v0''t']:\n",
    "                arr = self.choose_data(__feature, i)\n",
    "            else:\n",
    "                arr = self.test_data.iloc[np.sort(np.random.choice(self.test_data.shape[0], \n",
    "                                                                   self.num_vals, replace=False))]\n",
    "            for __explainer in self.explainers:\n",
    "                if self.explainer_type=='shap':\n",
    "                    __atts = self.explainers[__explainer].shap_values(arr)\n",
    "                if self.explainer_type=='lime':\n",
    "                    __atts = self.explainers[__explainer].attributions(arr)\n",
    "                if self.explainer_type=='analytic':\n",
    "                    __atts = self.explainers[__explainer].feature_att(arr)\n",
    "                \n",
    "                for j, __contribution in enumerate(self.test_labels.columns):\n",
    "                    multi_index = [range(len(arr)), [__feature for i in range(len(arr))], \n",
    "                                   [__contribution for i in range(len(arr))],\n",
    "                                   [__explainer for i in range(len(arr))]]\n",
    "                    if first_run:\n",
    "                        self.feature_attributions = pd.DataFrame(__atts[j], \n",
    "                                                                 columns = self.test_data.columns, \n",
    "                                                                 index = pd.MultiIndex.from_arrays(multi_index, \n",
    "                                                                        names=('num', 'feature', 'contribution', 'model')))\n",
    "                        first_run = False\n",
    "                    else:\n",
    "                        self.feature_attributions = self.feature_attributions.append(pd.DataFrame(__atts[j], \n",
    "                                                                 columns = self.test_data.columns, \n",
    "                                                                 index = pd.MultiIndex.from_arrays(multi_index, \n",
    "                                                                        names=('num', 'feature', 'contribution', 'model'))))\n",
    "                    \n",
    "        return self.feature_attributions\n",
    "        \n",
    "    def exp_plot(self):\n",
    "        \"\"\"\n",
    "            Plotting routine to visualise the explainers' results. Plots individual\n",
    "            feature contribution for each model and each feature.\n",
    "        \"\"\"\n",
    "        f, axs = plt.subplots(self.test_labels.shape[1], self.test_data.shape[1], \n",
    "                              figsize=(4*self.test_data.shape[1], 8), \n",
    "                              gridspec_kw=dict(width_ratios=4*np.ones((self.test_data.shape[1]))))\n",
    "\n",
    "        for i, __feature in enumerate(self.test_data.columns):\n",
    "            for j, __contribution in enumerate(self.test_labels.columns):\n",
    "                for __model in self.models:\n",
    "                    sns.scatterplot(data = self.feature_attributions.xs((__feature, __contribution, __model), \n",
    "                                                      level=('feature', 'contribution', 'model')), \n",
    "                                    x = self.feature_attributions.xs((__feature, __contribution, 'true'), \n",
    "                                                   level=('feature', 'contribution', 'model')).index,\n",
    "                                    y = self.feature_attributions.xs((__feature, __contribution, __model), \n",
    "                                                 level=('feature', 'contribution', 'model'))[__feature],\n",
    "                                    label = __model, ax=axs[j,i])  \n",
    "                    \n",
    "                axs[j,i].set_title(r\"Feature Contribution of \"+__feature+\" to \"+__contribution+\"\")\n",
    "                axs[j,i].set_xlabel('Index [ ]')\n",
    "                axs[j,i].set_ylabel('Feature Contribution [ ]')\n",
    "\n",
    "        f.tight_layout()\n",
    "\n",
    "        f.savefig(\"Images/\"+self.explainer_type+\"_summary\"+self.suffix+\"_kernel_good.svg\", dpi='figure')\n",
    "    \n",
    "    def agg_func(self, X):\n",
    "        \"\"\"\n",
    "            Function by which data aggregation is performed.\n",
    "        \n",
    "            Inputs\n",
    "            -------\n",
    "            X : numpy.array, array of values for which the aggregation is performed.\n",
    "                Is a list of the values for a single feature, single contribution\n",
    "                and single model.\n",
    "                \n",
    "            Returns\n",
    "            -------\n",
    "            y : value of the aggregation f(X).\n",
    "        \"\"\"\n",
    "        return np.mean(np.abs(X))\n",
    "    \n",
    "    def aggregate(self):\n",
    "        \"\"\"\n",
    "            Performs data aggregation. Aggregates for each feature its contribution to\n",
    "            each output variable for a given model.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            agg_vals : pandas.DataFrame, aggregated feature importance.\n",
    "        \"\"\"\n",
    "        first_run = True\n",
    "        \n",
    "        for i, __contribution in enumerate(self.test_labels.columns):\n",
    "            for j, __model in enumerate(self.models):\n",
    "                for k, __feature in enumerate(self.test_data.columns):\n",
    "                    \n",
    "                    multi_index = [[__feature], [__contribution], [__model]]\n",
    "                    if first_run:\n",
    "                        self.agg_vals = pd.DataFrame(self.agg_func(\n",
    "                            self.feature_attributions.xs((__feature,\n",
    "                                                          __contribution,\n",
    "                                                          __model), \n",
    "                                                         level=('feature', 'contribution', 'model'))[__feature].values),\n",
    "                                                     columns = ['contrib'], \n",
    "                                                     index = pd.MultiIndex.from_arrays(multi_index, \n",
    "                                                                        names=('feature', 'contribution', 'model')))\n",
    "                    else:\n",
    "                        self.agg_vals = self.agg_vals.append(pd.DataFrame(self.agg_func(\n",
    "                            self.feature_attributions.xs((__feature,\n",
    "                                                          __contribution,\n",
    "                                                          __model), \n",
    "                                                         level=('feature', 'contribution', 'model'))[__feature].values),\n",
    "                                                     columns = ['contrib'], \n",
    "                                                     index = pd.MultiIndex.from_arrays(multi_index, \n",
    "                                                                        names=('feature', 'contribution', 'model'))))\n",
    "                    first_run = False\n",
    "                    \n",
    "                    \n",
    "        return self.agg_vals\n",
    "    \n",
    "    def agg_plot(self):\n",
    "        \"\"\"\n",
    "            Plotting routine to visualise the aggregated feature importance.\n",
    "        \"\"\"\n",
    "        f, axs = plt.subplots(len(self.models), self.test_labels.shape[1], \n",
    "                              figsize=(6*self.test_labels.shape[1], 4*len(self.models)), \n",
    "                              gridspec_kw=dict(width_ratios=4*np.ones((self.test_labels.shape[1]))))\n",
    "        \n",
    "        for i, __model in enumerate(self.models):\n",
    "            for j, __contribution in enumerate(self.test_labels):\n",
    "                sns.barplot(data = self.agg_vals.xs((__contribution, __model), level=('contribution', 'model')),\n",
    "                    x = self.agg_vals.xs((__contribution, __model), level=('contribution', 'model')).index,\n",
    "                    y = 'contrib', label = __model, ax=axs[i,j])\n",
    "                axs[i,j].set_title(r\"Aggregate Feature Contribution to \"+__contribution+\" in the \"+__model+\" Model\")\n",
    "                axs[i,j].set_ylabel('Feature Contribution [ ]')\n",
    "\n",
    "        f.tight_layout()\n",
    "        f.savefig(\"Images/\"+self.explainer_type+\"_aggregated\"+self.suffix+\".svg\", dpi='figure')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "59ab9a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'alpha' : [-1],'beta' : [1], 'gamma' :[0.37], 'delta' : [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], 'omega' : [1.2]}\n",
    "\n",
    "\n",
    "suffix = \"local_testing_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "16a79508",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = DataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54094a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "d63f0f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Data…: 100%|██████████████████| 100/100 [00:18<00:00,  5.51it/s]\n"
     ]
    }
   ],
   "source": [
    "X, y = generator.generate(params = parameters, num_samples = int(1e2), samples = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "02c37bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = MinMaxScaler(feature_range=[0,2])\n",
    "\n",
    "X2 = scaler2.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "25dee7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X.loc[:,'x0':'t'].values)\n",
    "X_scaled = scaler.transform(X.loc[:,'x0':'t'].values, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "34bdcc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_model = TrueModel(scaler2, X, params = parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6884802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = fwg.wilke_explainer({'ml': true_model}, X, X, y, suffix = suffix, data_tol=0.1, num_vals=100, \n",
    "                 explainer_type='shap', background_resolution=100, tolerance=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b7963b",
   "metadata": {},
   "source": [
    "# The Monster Dataset:\n",
    "\n",
    "The Vision:\n",
    "    \n",
    "    Dataset with 100 random samples for each: t, alpha, beta, gamma, delta, omega\n",
    "    \n",
    "    At least 10 values for each of the above.\n",
    "    \n",
    "    Slider Plot with sliders for each of the above.\n",
    "    \n",
    "    For each setting: \n",
    "        Calculate SHAP Values\n",
    "        Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "7231a2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha' : [-1,1,10],'beta' : [1,1,1], 'gamma' :[0,1,10], 'delta' : [0,1,10], 'omega' : [1.2,1.2,1]}\n",
    "\n",
    "parameters1 = {'alpha': [np.linspace(params['alpha'][0],params['alpha'][1],params['alpha'][2])],\n",
    "                          'beta': [np.linspace(params['beta'][0],params['beta'][1],params['beta'][2])],\n",
    "                          'gamma': [np.linspace(params['gamma'][0],params['gamma'][1],params['gamma'][2])],\n",
    "                          'delta': [np.linspace(params['delta'][0],params['delta'][1],params['delta'][2])],\n",
    "                          'omega': [np.linspace(params['omega'][0],params['omega'][1],params['omega'][2])]\n",
    "                          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "968a014d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters1['alpha'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "3aacfe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonsterDataGenerator():\n",
    "    def __init__(self, features = ['x0','v0','t','rand'], \n",
    "                 labels = ['xt','vt'], \n",
    "                 x_range=[-2,2], v_range = [-1,1]):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.x_range = x_range\n",
    "        self.v_range = v_range\n",
    "    \n",
    "    def generate(self, num_samples = int(5e1), delay=0, samples=10, end_time=100, \n",
    "                 params = {'alpha' : [-1,-1,1],'beta' : [1,1,1], 'gamma' :[0,1,10], 'delta' : [0,1,10], 'omega' : [1.2,1.2,1]}):\n",
    "        \"\"\"\n",
    "            Generates training samples using scipy.integrate.odeint\n",
    "            to calculate the temporal evolution of a Duffing system.\n",
    "    \n",
    "            Samples randomly from x0 in [-2,2], v0 in [-1,1].\n",
    "    \n",
    "            For each set of initial conditions we generate a trajectory.\n",
    "            The trajectory is randomly sampled to generate training\n",
    "            pairs: X = (x0,v0,t), y = (xt,vt)\n",
    "    \n",
    "            Input\n",
    "            ----------\n",
    "            num_samples : int, number of training\n",
    "                            samples to be generated\n",
    "    \n",
    "            Returns\n",
    "            ----------\n",
    "            X : array((num_samples,3)), each entry in the array\n",
    "                is a training sample (x0,v0,t)\n",
    "            y : array((num_samples,2)), each entry in the array\n",
    "                is a target sample (xt,vt)\n",
    "        \"\"\"\n",
    "        self.parameters = {'alpha': [np.linspace(params['alpha'][0],params['alpha'][1],params['alpha'][2])],\n",
    "                          'beta': [np.linspace(params['beta'][0],params['beta'][1],params['beta'][2])],\n",
    "                          'gamma': [np.linspace(params['gamma'][0],params['gamma'][1],params['gamma'][2])],\n",
    "                          'delta': [np.linspace(params['delta'][0],params['delta'][1],params['delta'][2])],\n",
    "                          'omega': [np.linspace(params['omega'][0],params['omega'][1],params['omega'][2])]\n",
    "                          }\n",
    "        #Initialise the output arrays\n",
    "        self.parameter_length = 1\n",
    "        for key in self.parameters:\n",
    "            self.parameter_length  *= len(self.parameters[key][0]) \n",
    "        print(self.parameter_length)\n",
    "        #print(len(self.features)+len(params))\n",
    "        self.X = np.empty((num_samples*self.parameter_length*samples, (len(self.features)+len(params))))\n",
    "        self.y = np.empty((num_samples*self.parameter_length*samples, len(self.labels)))\n",
    "        complete_feature_vec = self.features.copy()\n",
    "        for k in params:\n",
    "            complete_feature_vec.append(k)\n",
    "        #Define bounds of the sampling\n",
    "        x_min = self.x_range[0]\n",
    "        x_max = self.x_range[1]\n",
    "        v_min = self.v_range[0]\n",
    "        v_max = self.v_range[1]\n",
    "        #Define the t_range to draw from\n",
    "        t_range = np.linspace(0, end_time, 100, endpoint=False)\n",
    "        t_vals = [int(100/samples*i) for i in range(samples)]\n",
    "        #Generate num_samples samples\n",
    "        ticker = 0\n",
    "        for alpha in self.parameters['alpha'][0]:\n",
    "            for beta in self.parameters['beta'][0]:\n",
    "                for gamma in self.parameters['gamma'][0]:\n",
    "                    for delta in self.parameters['delta'][0]:\n",
    "                        for omega in self.parameters['omega'][0]:\n",
    "                            self.current_params = {'alpha' : alpha,'beta' : beta, 'delta' : delta, \n",
    "                                                       'gamma' :gamma, 'omega' : omega}\n",
    "                            \n",
    "                             \n",
    "                            for i in tqdm(range(num_samples), desc=\"Generating Data…\", ascii=False, ncols=75):\n",
    "                                #Generate random starting positions\n",
    "                                x0 = (x_max - x_min) * np.random.random_sample() + x_min\n",
    "                                v0 = (v_max - v_min) * np.random.random_sample() + v_min \n",
    "                                #Generate a trajectory\n",
    "                                trajectory = odeint(self.eom, [x0,v0], t_range)\n",
    "                                for j, t_ind in enumerate(t_vals):\n",
    "                                    #print(str(i) + \", \" + str(j)+ \", \" +str(t_ind))\n",
    "                                    self.X[j+i*samples+ticker*num_samples*samples,:] = [x0, v0, t_range[t_ind], np.random.sample(), \n",
    "                                                                            alpha, beta, gamma, delta, omega]\n",
    "                                    self.y[j+i*samples+ticker*num_samples*samples,:] = trajectory[t_ind,:]\n",
    "                            ticker +=1        \n",
    "                                    \n",
    "                                    \n",
    "        \n",
    "        \n",
    "        self.X = pd.DataFrame(self.X, columns = complete_feature_vec)\n",
    "        self.y = pd.DataFrame(self.y, columns = self.labels)\n",
    "        return self.X, self.y\n",
    "\n",
    "\n",
    "    def save(self, suffix=None, filepath = \"Data/\"):\n",
    "        self.X.to_csv(filepath+\"X\"+suffix+\".csv\")\n",
    "        self.y.to_csv(filepath+\"y\"+suffix+\".csv\")\n",
    "        \n",
    "    def eom(self, u, t):\n",
    "        \"\"\"\n",
    "            Duffing Oscillator Equation of Motion\n",
    "    \n",
    "            ddx + delta * dx**2 + alpha * x + beta * x**3 = gamma * cos(omega * t)\n",
    "    \n",
    "            Input\n",
    "            ----------\n",
    "            u : vector of length 2, (x,v)\n",
    "                Position and Velocity at time t\n",
    "            t : float, the time t\n",
    "    \n",
    "            Parameters\n",
    "            ----------\n",
    "            alpha : float, linear stiffness\n",
    "            beta  : float, non linearity in the restoring force\n",
    "            gamma : float, amplitude of the periodic driving force\n",
    "            delta : float, amount of damping\n",
    "            omega : float, angular frequency of the periodic driving force\n",
    "    \n",
    "            Returns\n",
    "            ----------\n",
    "            [dx,ddx] : Tuple, Time derivatives of \n",
    "                        position and velocity at time t\n",
    "    \n",
    "        \"\"\"\n",
    "        x, dx = u[0], u[1]\n",
    "        ddx = (self.current_params['gamma'] * np.cos(self.current_params['omega'] * t) - \n",
    "               (self.current_params['delta'] * dx + self.current_params['alpha'] * x + self.current_params['beta'] * x**3))\n",
    "    \n",
    "        return [dx,ddx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "1ae3d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "genner = MonsterDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "d76a6109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Data…:  10%|██                   | 5/50 [00:00<00:00, 45.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 52.80it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 92.08it/s]\n",
      "Generating Data…: 100%|███████████████████| 50/50 [00:00<00:00, 119.05it/s]\n",
      "Generating Data…: 100%|███████████████████| 50/50 [00:00<00:00, 144.09it/s]\n",
      "Generating Data…: 100%|███████████████████| 50/50 [00:00<00:00, 177.94it/s]\n",
      "Generating Data…: 100%|███████████████████| 50/50 [00:00<00:00, 215.52it/s]\n",
      "Generating Data…: 100%|███████████████████| 50/50 [00:00<00:00, 257.73it/s]\n",
      "Generating Data…: 100%|███████████████████| 50/50 [00:00<00:00, 294.12it/s]\n",
      "Generating Data…: 100%|███████████████████| 50/50 [00:00<00:00, 320.52it/s]\n",
      "Generating Data…: 100%|███████████████████| 50/50 [00:00<00:00, 362.26it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 56.95it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 68.96it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 76.04it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 83.89it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 86.51it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 87.57it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 90.25it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 92.93it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 94.70it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 93.72it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 47.51it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 68.97it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 69.25it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 68.45it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 69.93it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 74.18it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 79.62it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 81.97it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 82.92it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 85.47it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 46.60it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 60.31it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 69.35it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 73.75it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 66.67it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 68.12it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 71.02it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 73.10it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 74.29it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 77.76it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 42.86it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 48.66it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 67.11it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 70.83it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 73.64it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 66.40it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 66.84it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 68.50it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 71.48it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 70.42it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 39.40it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 40.42it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 59.04it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 61.50it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 70.22it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 75.99it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 70.42it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 65.70it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 66.67it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 69.78it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 38.96it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 37.13it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 43.18it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 60.53it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 60.14it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 73.31it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 72.67it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 73.25it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 66.40it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 66.40it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 38.46it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 36.58it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 37.31it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 52.19it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 58.65it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 59.31it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 67.39it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 70.11it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 76.22it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 67.94it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 36.79it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 36.15it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 37.23it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 37.53it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 53.56it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 59.31it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 60.75it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 63.29it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 68.95it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 74.07it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 36.16it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 35.77it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 36.47it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 36.43it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:01<00:00, 44.88it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 57.21it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 61.73it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 60.46it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 64.60it/s]\n",
      "Generating Data…: 100%|████████████████████| 50/50 [00:00<00:00, 70.08it/s]\n"
     ]
    }
   ],
   "source": [
    "X, y = genner.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "48508821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe9601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "864a40ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2129199d0a0>]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X['gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e02134a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df15199fc3cf44838628fb1ba8c21b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-194-64d75f6139fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_explainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\wilkeXAI\\wilke_shap.py\u001b[0m in \u001b[0;36meval_explainer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m__explainer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplainers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplainer_type\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'shap'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                     \u001b[0m__atts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplainers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m__explainer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplainer_type\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'lime'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                     \u001b[0m__atts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplainers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m__explainer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattributions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\shap\\explainers\\_kernel.py\u001b[0m in \u001b[0;36mshap_values\u001b[1;34m(self, X, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[1;31m# vector-output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplanations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "explainer.eval_explainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e9ec27fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "expleener = shap.KernelExplainer(true_model.predict, shap.sample(X2, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "2432d0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260be82682ad4cb8972c1eae55bdccf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap_vals = expleener.shap_values(X2[:100,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4fc34268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_data(feature, i, X):\n",
    "        \"\"\"\n",
    "            Chooses the data points on which the explainer will be evaluated for\n",
    "            a given feature. First, removes any points where the prediction is\n",
    "            further than tolerance from the true value. Second, takes values in\n",
    "            a band of thickness tol around 0 for all features not currently being\n",
    "            evaluated on. Third, chooses a random subset of length num_vals of \n",
    "            these values. This function should never be called outside of this class.\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            i : int, index of the feature being explained\n",
    "            feature : str, the feature being explained\n",
    "            num_features : the total number of features\n",
    "            \n",
    "            Returns\n",
    "            ----------\n",
    "            data_arr : pandas.DataFrame, array of the chosen values.\n",
    "        \"\"\"\n",
    "        tol = 0.1\n",
    "        num_vals = 100\n",
    "        where__ = np.ones_like(X[feature].values, dtype=bool)\n",
    "        \n",
    "        for j in range(1,3):\n",
    "            where__ = np.multiply(where__, np.abs(X.values[:,(i + j)%3])<tol)\n",
    "        data_arr = X.iloc[where__]\n",
    "        data_arr = data_arr.iloc[np.sort(\n",
    "            np.random.choice(data_arr.shape[0], np.min([data_arr.shape[0]]), replace=False))]\n",
    "        return data_arr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "85fec265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0626333 , 0.33885701, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.0626333 , 0.33885701, 0.00400802, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.0626333 , 0.33885701, 0.00801603, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.36023036, 0.        , 1.99198397, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.36023036, 0.        , 1.99599198, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.36023036, 0.        , 2.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "994587ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-216-cc73b194e53f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mexplainer_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'shap'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfirst_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m__feature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m__feature\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'x0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'v0'\u001b[0m\u001b[1;34m't'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchoose_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "explainer_type = 'shap'\n",
    "first_run = True\n",
    "for i, __feature in enumerate(X2.columns):\n",
    "    if __feature in ['x0','v0''t']:\n",
    "        arr = choose_data(__feature, i, X2)\n",
    "    else:\n",
    "        arr = X.iloc[np.sort(np.random.choice(X2.shape[0], 100, replace=False))]\n",
    "    if explainer_type=='shap':\n",
    "        __atts = expleener.shap_values(arr)\n",
    "    if explainer_type=='lime':\n",
    "        __atts = self.explainers[__explainer].attributions(arr)\n",
    "    if explainer_type=='analytic':\n",
    "        __atts = self.explainers[__explainer].feature_att(arr)\n",
    "\n",
    "    for j, __contribution in enumerate(y.columns):\n",
    "                        multi_index = [range(len(shap_vals)), [__feature for i in range(len(shap_vals))], \n",
    "                                       [__contribution for i in range(len(shap_vals))],\n",
    "                                       [__explainer for i in range(len(shap_vals))]]\n",
    "                        if first_run:\n",
    "                            shap_vals_arr = pd.DataFrame(shap_vals[j], \n",
    "                                                                     columns = y.columns, \n",
    "                                                                     index = pd.MultiIndex.from_arrays(multi_index, \n",
    "                                                                            names=('num', 'feature', 'contribution', 'model')))\n",
    "                            first_run = False\n",
    "                        else:\n",
    "                            shap_vals_arr = shap_vals_arr.append(pd.DataFrame(shap_vals[j], \n",
    "                                                                     columns = self.test_data.columns, \n",
    "                                                                     index = pd.MultiIndex.from_arrays(multi_index, \n",
    "                                                                            names=('num', 'feature', 'contribution', 'model'))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "95b3e2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.13164111, -0.66402649],\n",
       "       [ 0.00819183, -0.5773278 ],\n",
       "       [-0.10063379, -0.51773135],\n",
       "       [-0.20035837, -0.48625573],\n",
       "       [-0.29665373, -0.48341944],\n",
       "       [-0.39524091, -0.50911872],\n",
       "       [-0.50169759, -0.56183409],\n",
       "       [-0.62103914, -0.6371351 ],\n",
       "       [-0.7569193 , -0.7253462 ],\n",
       "       [-0.91028478, -0.80847995],\n",
       "       [-1.07742412, -0.85757127],\n",
       "       [-1.24777744, -0.83372384],\n",
       "       [-1.40277803, -0.69835283],\n",
       "       [-1.51795915, -0.43534612],\n",
       "       [-1.56995246, -0.07461485],\n",
       "       [-1.5462739 ,  0.30783834],\n",
       "       [-1.45145499,  0.62557809],\n",
       "       [-1.3044289 ,  0.82663003],\n",
       "       [-1.12939853,  0.90958734],\n",
       "       [-0.94703046,  0.90698002],\n",
       "       [-0.77026395,  0.86002613],\n",
       "       [-0.60435271,  0.80298558],\n",
       "       [-0.44882988,  0.7588842 ],\n",
       "       [-0.29963192,  0.74124175],\n",
       "       [-0.15067998,  0.75723536],\n",
       "       [ 0.00511746,  0.81012444],\n",
       "       [ 0.17519805,  0.90009806],\n",
       "       [ 0.36664059,  1.02291683],\n",
       "       [ 0.58489307,  1.16540904],\n",
       "       [ 0.83121201,  1.29703444],\n",
       "       [ 1.09814554,  1.35957887],\n",
       "       [ 1.36357975,  1.26603291],\n",
       "       [ 1.58736863,  0.93191772],\n",
       "       [ 1.71876391,  0.34983504],\n",
       "       [ 1.71887246, -0.35169317],\n",
       "       [ 1.58428935, -0.96694431],\n",
       "       [ 1.34805417, -1.35917736],\n",
       "       [ 1.05660917, -1.53030643],\n",
       "       [ 0.74605944, -1.56764496],\n",
       "       [ 0.43333013, -1.5659082 ],\n",
       "       [ 0.11915735, -1.58990499],\n",
       "       [-0.20509574, -1.6688752 ],\n",
       "       [-0.55031085, -1.79513814],\n",
       "       [-0.92120813, -1.91135567],\n",
       "       [-1.30434398, -1.89024544],\n",
       "       [-1.65433108, -1.54824174],\n",
       "       [-1.89265027, -0.76878285],\n",
       "       [-1.94121966,  0.30155956],\n",
       "       [-1.77894301,  1.27563249],\n",
       "       [-1.45844877,  1.86387336],\n",
       "       [-1.06004175,  2.07965204],\n",
       "       [-0.64078947,  2.10589742],\n",
       "       [-0.22055367,  2.11138382],\n",
       "       [ 0.20670012,  2.1835045 ],\n",
       "       [ 0.65564893,  2.32046357],\n",
       "       [ 1.13033368,  2.41205443],\n",
       "       [ 1.59945172,  2.21396237],\n",
       "       [ 1.97505258,  1.4379518 ],\n",
       "       [ 2.13385084,  0.08742348],\n",
       "       [ 2.00610109, -1.31886934],\n",
       "       [ 1.64271997, -2.21444118],\n",
       "       [ 1.16138378, -2.5316768 ],\n",
       "       [ 0.65167888, -2.55247954],\n",
       "       [ 0.14394052, -2.54527884],\n",
       "       [-0.37089515, -2.63058661],\n",
       "       [-0.9100839 , -2.76803559],\n",
       "       [-1.46442563, -2.72597484],\n",
       "       [-1.95924757, -2.100915  ],\n",
       "       [-2.24704308, -0.66113678],\n",
       "       [-2.19956271,  1.11636871],\n",
       "       [-1.83777224,  2.37293946],\n",
       "       [-1.30640353,  2.83872001],\n",
       "       [-0.73456116,  2.85266419],\n",
       "       [-0.17191122,  2.79436643],\n",
       "       [ 0.38816108,  2.83746476],\n",
       "       [ 0.96521393,  2.93906027],\n",
       "       [ 1.54755712,  2.82438808],\n",
       "       [ 2.04779058,  2.04186497],\n",
       "       [ 2.30394132,  0.41014499],\n",
       "       [ 2.1967338 , -1.43220173],\n",
       "       [ 1.77981   , -2.59190582],\n",
       "       [ 1.21813743, -2.92818038],\n",
       "       [ 0.6375199 , -2.85996201],\n",
       "       [ 0.07811016, -2.75829658],\n",
       "       [-0.47111443, -2.76296272],\n",
       "       [-1.0277362 , -2.80379384],\n",
       "       [-1.57486568, -2.60584746],\n",
       "       [-2.0255689 , -1.77968266],\n",
       "       [-2.23600967, -0.2409186 ],\n",
       "       [-2.11435994,  1.40295798],\n",
       "       [-1.71993502,  2.41332301],\n",
       "       [-1.20027787,  2.6979996 ],\n",
       "       [-0.66724564,  2.61343216],\n",
       "       [-0.15994585,  2.47783313],\n",
       "       [ 0.32780418,  2.42588863],\n",
       "       [ 0.81296759,  2.43705894],\n",
       "       [ 1.29470434,  2.35417425],\n",
       "       [ 1.72872085,  1.91147858],\n",
       "       [ 2.02000779,  0.91585951],\n",
       "       [ 2.06978952, -0.4336295 ]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_model.predict(X2[:100,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e32a92a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xt</th>\n",
       "      <th>vt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.131641</td>\n",
       "      <td>-0.664026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019845</td>\n",
       "      <td>-0.464576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.057970</td>\n",
       "      <td>-0.321950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.111922</td>\n",
       "      <td>-0.224242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.150076</td>\n",
       "      <td>-0.162749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>-1.005353</td>\n",
       "      <td>0.328753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>-0.940287</td>\n",
       "      <td>0.319536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>-0.878343</td>\n",
       "      <td>0.298207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>-0.821587</td>\n",
       "      <td>0.268096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>-0.771556</td>\n",
       "      <td>0.231180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             xt        vt\n",
       "0      0.131641 -0.664026\n",
       "1      0.019845 -0.464576\n",
       "2     -0.057970 -0.321950\n",
       "3     -0.111922 -0.224242\n",
       "4     -0.150076 -0.162749\n",
       "...         ...       ...\n",
       "49995 -1.005353  0.328753\n",
       "49996 -0.940287  0.319536\n",
       "49997 -0.878343  0.298207\n",
       "49998 -0.821587  0.268096\n",
       "49999 -0.771556  0.231180\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592157a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_plot(X, y, atts):\n",
    "        \"\"\"\n",
    "            Plotting routine to visualise the explainers' results. Plots individual\n",
    "            feature contribution for each model and each feature.\n",
    "        \"\"\"\n",
    "        f, axs = plt.subplots(y.test_labels.shape[1], X.test_data.shape[1], \n",
    "                              figsize=(4*X.test_data.shape[1], 8), \n",
    "                              gridspec_kw=dict(width_ratios=4*np.ones((X.test_data.shape[1]))))\n",
    "\n",
    "        for i, __feature in enumerate(X.test_data.columns):\n",
    "            for j, __contribution in enumerate(y.test_labels.columns):\n",
    "                sns.scatterplot(data = atts.xs((__feature, __contribution), \n",
    "                                                  level=('feature', 'contribution', 'model')), \n",
    "                                x = atts.xs((__feature, __contribution, 'true'), \n",
    "                                               level=('feature', 'contribution', 'model')).index,\n",
    "                                y = atts.xs((__feature, __contribution), \n",
    "                                             level=('feature', 'contribution', 'model'))[__feature],\n",
    "                                label = '__model', ax=axs[j,i])  \n",
    "                    \n",
    "                axs[j,i].set_title(r\"Feature Contribution of \"+__feature+\" to \"+__contribution+\"\")\n",
    "                axs[j,i].set_xlabel('Index [ ]')\n",
    "                axs[j,i].set_ylabel('Feature Contribution [ ]')\n",
    "\n",
    "        f.tight_layout()\n",
    "\n",
    "        #f.savefig(\"Images/\"+self.explainer_type+\"_summary\"+self.suffix+\"_kernel_good.svg\", dpi='figure')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
