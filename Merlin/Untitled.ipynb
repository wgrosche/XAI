{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd69a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# True Model\n",
    "from scipy.integrate import odeint\n",
    "from scipy.fft import fft\n",
    "\n",
    "# Machine Learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# Data Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# My Modules\n",
    "from wilkeXAI.data_generator import DataGenerator\n",
    "import wilkeXAI.wilke_shap as fwg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78eeeb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define and Machine Learning Model\n",
    "\"\"\"\n",
    "\n",
    "def MLModel():\n",
    "    opt = Adam(learning_rate=0.001, beta_1=0.7)\n",
    "    loss='mse'\n",
    "    model = Sequential([\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(32, activation='sigmoid'),\n",
    "        layers.Dense(32, activation='tanh'),\n",
    "        layers.Dense(2)            \n",
    "    ])\n",
    "    model.compile(optimizer=opt, loss=loss)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2b3c0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Data…: 100%|██████████████| 10000/10000 [02:28<00:00, 67.54it/s]\n",
      "Generating Data…: 100%|████████████████| 1000/1000 [00:14<00:00, 67.49it/s]\n"
     ]
    }
   ],
   "source": [
    "suffix = \"Run_1\"\n",
    "generator = DataGenerator()\n",
    "# Generate the data\n",
    "X_train, y_train = generator.generate(num_samples=int(1e4))\n",
    "X_test, y_test = generator.generate(num_samples=int(1e3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bbf0a077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>v0</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.015976</td>\n",
       "      <td>0.701215</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.015976</td>\n",
       "      <td>0.701215</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.015976</td>\n",
       "      <td>0.701215</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.015976</td>\n",
       "      <td>0.701215</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.015976</td>\n",
       "      <td>0.701215</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999995</th>\n",
       "      <td>0.437671</td>\n",
       "      <td>0.225635</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999996</th>\n",
       "      <td>0.437671</td>\n",
       "      <td>0.225635</td>\n",
       "      <td>99.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999997</th>\n",
       "      <td>0.437671</td>\n",
       "      <td>0.225635</td>\n",
       "      <td>99.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999998</th>\n",
       "      <td>0.437671</td>\n",
       "      <td>0.225635</td>\n",
       "      <td>99.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999999</th>\n",
       "      <td>0.437671</td>\n",
       "      <td>0.225635</td>\n",
       "      <td>99.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               x0        v0     t\n",
       "0       -1.015976  0.701215   0.0\n",
       "1       -1.015976  0.701215   0.2\n",
       "2       -1.015976  0.701215   0.4\n",
       "3       -1.015976  0.701215   0.6\n",
       "4       -1.015976  0.701215   0.8\n",
       "...           ...       ...   ...\n",
       "4999995  0.437671  0.225635  99.0\n",
       "4999996  0.437671  0.225635  99.2\n",
       "4999997  0.437671  0.225635  99.4\n",
       "4999998  0.437671  0.225635  99.6\n",
       "4999999  0.437671  0.225635  99.8\n",
       "\n",
       "[5000000 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[:,'x0':'t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eac896ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.32969714,  0.21075447, -1.72859016],\n",
       "       [-0.32969714,  0.21075447, -1.72166195],\n",
       "       [-0.32969714,  0.21075447, -1.71473373],\n",
       "       ...,\n",
       "       [ 1.07581826, -0.90680433,  1.71473373],\n",
       "       [ 1.07581826, -0.90680433,  1.72166195],\n",
       "       [ 1.07581826, -0.90680433,  1.72859016]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train.loc[:,'x0':'t'].values)\n",
    "scaler.transform(X_train.loc[:,'x0':'t'].values, copy=False)\n",
    "scaler.transform(X_test.loc[:,'x0':'t'].values, copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e980f883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.32969714,  0.21075447, -1.72859016],\n",
       "       [-0.32969714,  0.21075447, -1.72166195],\n",
       "       [-0.32969714,  0.21075447, -1.71473373],\n",
       "       ...,\n",
       "       [ 1.07581826, -0.90680433,  1.71473373],\n",
       "       [ 1.07581826, -0.90680433,  1.72166195],\n",
       "       [ 1.07581826, -0.90680433,  1.72859016]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.values[:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c80da1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLModel()\n",
    "true_model = fwg.TrueModel(scaler, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4736ca4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "197/197 - 25s - loss: 0.0895 - val_loss: 0.0678\n",
      "\n",
      "Epoch 00001: saving model to Networks\\training\n",
      "Epoch 2/3\n",
      "197/197 - 25s - loss: 0.0688 - val_loss: 0.0681\n",
      "\n",
      "Epoch 00002: saving model to Networks\\training\n",
      "Epoch 3/3\n",
      "197/197 - 24s - loss: 0.0677 - val_loss: 0.0662\n",
      "\n",
      "Epoch 00003: saving model to Networks\\training\n"
     ]
    }
   ],
   "source": [
    "# Train Network\n",
    "# Model Weights Path\n",
    "checkpoint_path = \"Networks//training//\"+suffix+\"cp1.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_dir,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "callbacks = [cp_callback,\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15),\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15)]\n",
    "\n",
    "\n",
    "history=model.fit(X_train, y_train, steps_per_epoch=None, epochs=3, \n",
    "                  validation_split=0.2, batch_size=20364, shuffle=True, callbacks=callbacks, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8dcf8163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x0', 'v0', 't', 'rand'], dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4e2c7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222c626da5c948f3abd284fa84d5541b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e137ba55676e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mexp_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'shap'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lime'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'analytic'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mexplainer_curr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfwg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwilke_explainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexplainer_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexp_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mexplainer_curr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_explainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Results/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mexp_type\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/individual/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mexplainer_curr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Results/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mexp_type\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/aggregate/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\wilkeXAI\\wilke_shap.py\u001b[0m in \u001b[0;36meval_explainer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m__explainer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplainers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplainer_type\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'shap'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m                     \u001b[0m__atts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplainers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m__explainer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplainer_type\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'lime'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m                     \u001b[0m__atts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplainers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m__explainer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattributions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\shap\\explainers\\_kernel.py\u001b[0m in \u001b[0;36mshap_values\u001b[1;34m(self, X, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[1;31m# vector-output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplanations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "models = {'ml': model, \n",
    "         'true': true_model}\n",
    "       \n",
    "for exp_type in ['shap', 'lime', 'analytic']:\n",
    "    explainer_curr = fwg.wilke_explainer(models, X_train, X_test, y_test, explainer_type=exp_type, tolerance = 1)\n",
    "    explainer_curr.eval_explainer().to_csv(\"Results/\"+exp_type+\"/individual/\"+suffix+\".csv\")\n",
    "    explainer_curr.aggregate().to_csv(\"Results/\"+exp_type+\"/aggregate/\"+suffix+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fdf77d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_test = fwg.wilke_explainer(models, X_train, X_test, y_test, explainer_type='shap', tolerance = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0a89beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose_vals(0,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9aad110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_vals(i, num_features):\n",
    "        \"\"\"\n",
    "            Chooses the data points on which the explainer will be evaluated for\n",
    "            a given feature. First, removes any points where the prediction is\n",
    "            further than tolerance from the true value. Second, takes values in\n",
    "            a band of thickness tol around 0 for all features not currently being\n",
    "            evaluated on. Third, chooses a random subset of length num_vals of \n",
    "            these values. This function should never be called outside of this class.\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            i : int, index of the feature being explained\n",
    "            feature : str, the feature being explained\n",
    "            num_features : the total number of features\n",
    "            \n",
    "            Returns\n",
    "            ----------\n",
    "            data_arr : pandas.DataFrame, array of the chosen values.\n",
    "        \"\"\"\n",
    "        vals = np.abs(np.linalg.norm((models['ml']).predict(X_test), axis=1) - \n",
    "                      np.linalg.norm(y_test, axis=1))\n",
    "        data_arr = X_test.iloc[np.where(vals < 0.1)]\n",
    "        where__ = np.ones_like(data_arr.values[:,i], dtype=bool)\n",
    "        for j in range(1,num_features):\n",
    "            where__ = np.multiply(where__, np.abs(data_arr.values[:,(i + j)%num_features])<self.tol)\n",
    "        return where__\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fac733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_data(i, num_features):\n",
    "        \"\"\"\n",
    "            Chooses the data points on which the explainer will be evaluated for\n",
    "            a given feature. First, removes any points where the prediction is\n",
    "            further than tolerance from the true value. Second, takes values in\n",
    "            a band of thickness tol around 0 for all features not currently being\n",
    "            evaluated on. Third, chooses a random subset of length num_vals of \n",
    "            these values. This function should never be called outside of this class.\n",
    "            \n",
    "            Parameters\n",
    "            ----------\n",
    "            i : int, index of the feature being explained\n",
    "            feature : str, the feature being explained\n",
    "            num_features : the total number of features\n",
    "            \n",
    "            Returns\n",
    "            ----------\n",
    "            data_arr : pandas.DataFrame, array of the chosen values.\n",
    "        \"\"\"\n",
    "        vals = np.abs(np.linalg.norm((models['ml']).predict(X_test), axis=1) - \n",
    "                      np.linalg.norm(y_test, axis=1))\n",
    "        \n",
    "        print(vals)\n",
    "        data_arr = self.test_data.iloc[np.where(vals < self.tolerance)]\n",
    "        where__ = np.ones_like(data_arr.values[:,i], dtype=bool)\n",
    "        for j in range(1,num_features):\n",
    "            where__ = np.multiply(where__, np.abs(data_arr.values[:,(i + j)%num_features])<self.tol)\n",
    "        data_arr = data_arr.iloc[where__]\n",
    "        data_arr = data_arr.iloc[np.sort(\n",
    "            np.random.choice(data_arr.shape[0], np.min([self.num_vals, data_arr.shape[0]]), replace=False))]\n",
    "        return data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c48b3252",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-4136586ddc43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwhere__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data_arr' is not defined"
     ]
    }
   ],
   "source": [
    "where__ = np.ones_like(data_arr.values[:,i], dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc15b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha' : [-1],'beta' : [1], 'gamma' :[0.37], 'delta' : [1], 'omega' : [1.2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93a14681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37\n"
     ]
    }
   ],
   "source": [
    "for beta in params['gamma']:\n",
    "    print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af707312",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'set_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-26fd4f221856>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alpha'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'beta'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gamma'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'delta'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'omega'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'set_index'"
     ]
    }
   ],
   "source": [
    "X_test.set_index(['alpha', 'beta', 'gamma', 'delta', 'omega'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d263a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.inverse_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba275fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.95477679, -0.70577194,  0.        , ...,  0.37      ,\n",
       "         1.        ,  1.2       ],\n",
       "       [-1.95477679, -0.70577194,  0.2       , ...,  0.37      ,\n",
       "         1.        ,  1.2       ],\n",
       "       [-1.95477679, -0.70577194,  0.4       , ...,  0.37      ,\n",
       "         1.        ,  1.2       ],\n",
       "       ...,\n",
       "       [ 0.12764016,  0.75095404, 99.4       , ...,  0.37      ,\n",
       "         1.        ,  1.2       ],\n",
       "       [ 0.12764016,  0.75095404, 99.6       , ...,  0.37      ,\n",
       "         1.        ,  1.2       ],\n",
       "       [ 0.12764016,  0.75095404, 99.8       , ...,  0.37      ,\n",
       "         1.        ,  1.2       ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a863a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
