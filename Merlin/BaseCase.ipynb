{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53abea00",
   "metadata": {},
   "source": [
    "Base Case:\n",
    "\n",
    "Features: (x0,v0,t)\n",
    "Labels: (xt,vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e81f8bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from scipy.integrate import odeint, solve_ivp\n",
    "from scipy.fft import fft\n",
    "\n",
    "\n",
    "import shap as shap\n",
    "try:\n",
    "    import lime\n",
    "    import lime.lime_tabular    \n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Machine Learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow import keras\n",
    "\n",
    "# for reproducibility of this notebook:\n",
    "rng = np.random.RandomState(42)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64ea8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Duffing():\n",
    "    \"\"\"\n",
    "        Class for the Duffing Oscillator\n",
    "    \"\"\"\n",
    "    def __init__(self, parameters = {'alpha': [0.3], 'beta': [-0.1], 'gamma': [0.37], 'delta': [0.3], 'omega': [1.2]}, \n",
    "                 labels = ['xt','vt'], features = ['x0','v0', 't'], scaler = None):\n",
    "        \"\"\"\n",
    "            Define Parameter Configuration to Model\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            alpha : float, linear stiffness\n",
    "            beta  : float, non linearity in the restoring force\n",
    "            gamma : float, amplitude of the periodic driving force\n",
    "            delta : float, amount of damping\n",
    "            omega : float, angular frequency of the periodic driving force\n",
    "        \"\"\"   \n",
    "        self.labels = labels\n",
    "        self.parameters = parameters\n",
    "        self.features = features\n",
    "        self.scaler = scaler\n",
    "        self.suffix = \"params_\"+str(parameters['alpha'])+\"_\"+str(parameters['beta'])+\"_\"+str(parameters['gamma'])+\"_\"+str(parameters['delta'])+\"_\"+str(parameters['omega'])\n",
    "\n",
    "        \n",
    "    def eom(self, t, u):\n",
    "        \"\"\"\n",
    "            Duffing Oscillator Equation of Motion\n",
    "\n",
    "            ddx + delta * dx + alpha * x + beta * x**3 = gamma * cos(omega * t)\n",
    "\n",
    "            Input\n",
    "            ----------\n",
    "            u : vector of length 2, (x,v)\n",
    "                Position and Velocity at time t\n",
    "            t : float, the time t\n",
    "\n",
    "            Returns\n",
    "            ----------\n",
    "            [dx,ddx] : Tuple, Time derivatives of \n",
    "                        position and velocity at time t\n",
    "        \"\"\"\n",
    "        x, dx = u[0], u[1]\n",
    "        ddx = (self.parameters['gamma'] * np.cos(self.parameters['omega'] * t) - (self.parameters['delta'] * dx + self.parameters['alpha'] * x + self.parameters['beta'] * x**3))\n",
    "\n",
    "        return [dx,ddx]\n",
    "    \n",
    "    def energy(self, x, v):\n",
    "        return 0.5*v**2 + 0.5*self.parameters['alpha']*x**2 +0.25*self.parameters['beta']*x**4\n",
    "\n",
    "    def termination_event(self, t, y):\n",
    "        \"\"\"\n",
    "            Stops Numerical Integration once points wander too far away\n",
    "        \"\"\"\n",
    "        return (np.abs(y[0]) - 10)*(np.abs(y[1]) - 10)\n",
    "    termination_event.terminal = True\n",
    "\n",
    "\n",
    "    def generate(self, num_samples = int(5e1), samples=10, end_time=100, gridded=False, num_gammas = 1):\n",
    "        \"\"\"\n",
    "            Generates training samples using scipy.integrate.odeint\n",
    "            to calculate the temporal evolution of a Duffing system.\n",
    "    \n",
    "            Samples randomly from x0 in [-2,2], v0 in [-1,1].\n",
    "    \n",
    "            For each set of initial conditions we generate a trajectory.\n",
    "            The trajectory is randomly sampled to generate training\n",
    "            pairs: X = (x0,v0,t), y = (xt,vt)\n",
    "    \n",
    "            Input\n",
    "            ----------\n",
    "            num_samples : int, number of training\n",
    "                            samples to be generated\n",
    "    \n",
    "            Returns\n",
    "            ----------\n",
    "            X : array((num_samples,3)), each entry in the array\n",
    "                is a training sample (x0,v0,t)\n",
    "            y : array((num_samples,2)), each entry in the array\n",
    "                is a target sample (xt,vt)\n",
    "        \"\"\"\n",
    "        self.scaler = None\n",
    "        #Define bounds of the sampling\n",
    "        x_min = -2\n",
    "        x_max = 2\n",
    "        v_min = -2\n",
    "        v_max = 2\n",
    "        #Initialise the output arrays        \n",
    "        X = np.empty((num_samples*samples, len(np.hstack((self.features, self.labels)))))\n",
    "        #Define the t_range to draw from\n",
    "        t_range = np.linspace(0, end_time, 100, endpoint=False)\n",
    "        t_vals = np.sort(np.random.choice(t_range, size = samples, replace=False))\n",
    "\n",
    "        #Generate num_samples samples\n",
    "        for i in tqdm(range(num_samples), desc=\"Generating Data…\", ascii=False, ncols=75):\n",
    "            #Generate random starting positions\n",
    "            x0 = (x_max - x_min) * np.random.random_sample() + x_min\n",
    "            v0 = (v_max - v_min) * np.random.random_sample() + v_min\n",
    "            # Do something with the current parameter combination in ``dict_``\n",
    "            #Generate a trajectory\n",
    "            trajectory = solve_ivp(self.eom, [0, end_time], [x0,v0], t_eval = t_vals, events = [self.termination_event])\n",
    "            traj_cutoff =  samples - len(trajectory.y[0])\n",
    "            traj_x = np.append(trajectory.y[0].reshape(-1,1), 10.0*np.ones(traj_cutoff).reshape(-1,1))\n",
    "            traj_v = np.append(trajectory.y[1].reshape(-1,1), 10.0*np.ones(traj_cutoff).reshape(-1,1))\n",
    "            X[i*samples:(i+1)*samples,:] = np.hstack((x0*np.ones(samples).reshape(-1,1), \n",
    "                                           v0*np.ones(samples).reshape(-1,1),\n",
    "                                           t_vals.reshape(-1,1),\n",
    "                                           traj_x.reshape(-1,1), \n",
    "                                           traj_v.reshape(-1,1)))\n",
    "        \n",
    "        self.X_df = pd.DataFrame(X, columns = np.hstack((self.features, self.labels)))\n",
    "        return self.X_df\n",
    "\n",
    "    def scale_features(self):\n",
    "        if self.scaler == None:\n",
    "            self.scaler = MinMaxScaler(feature_range=[0,1])\n",
    "            self.X_df[self.features] = self.scaler.fit_transform(self.X_df[self.features].values)\n",
    "        else: return\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.scaler == None:\n",
    "            self.scale_features()\n",
    "        if type(X) == pd.core.frame.DataFrame:\n",
    "            X_temp = pd.DataFrame(self.scaler.inverse_transform(X.values), columns=X.columns)\n",
    "        elif type(X) == np.ndarray:\n",
    "            X_temp = pd.DataFrame(self.scaler.inverse_transform(X), columns=self.features)\n",
    "\n",
    "        y = np.ones((np.shape(X_temp)[0], 2))\n",
    "        for i in range(0,np.shape(X_temp)[0]):\n",
    "            for j in self.parameters:\n",
    "                self.parameters[j] = X_temp[j].iloc[i]\n",
    "            traj = solve_ivp(self.eom, [0, X_temp['t'].iloc[i]], [X_temp['x0'].iloc[i], X_temp['v0'].iloc[i]], \n",
    "                            t_eval = None, events = [self.termination_event])\n",
    "            y[i] = [traj.y[0][-1], traj.y[1][-1]]\n",
    "            \n",
    "        return y\n",
    "\n",
    "    def predict_x(self, X):\n",
    "        return self.predict(X)[0]\n",
    "\n",
    "    def predict_v(self, X):          \n",
    "        return self.predict(X)[1]\n",
    "\n",
    "        \n",
    "    def vals_to_df(self, values, data, explainer = \"lime\", suffix = None):\n",
    "        df = pd.DataFrame(values[0], columns = [self.labels[0] + \"_\" + i for i in self.features])\n",
    "        df = df.join(pd.DataFrame(values[1], columns = [self.labels[1] + \"_\" + i for i in self.features]))\n",
    "        df = df.join(pd.DataFrame(data.values, columns = self.features))\n",
    "        df.insert(df.shape[1], 'explainer' ,[explainer for _ in range(df.shape[0])])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0df67b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumericExplainer():\n",
    "    \"\"\"\n",
    "        Pretty Brute force numerical gradient calculation for\n",
    "        explainability of a known function\n",
    "    \"\"\"\n",
    "    def __init__(self, f, features, labels,  h=0.01):\n",
    "        \"\"\"\n",
    "            Initialises with some configurations for the gradient calculation\n",
    "            as well as the function being differentiated.\n",
    "            \n",
    "            Inputs\n",
    "            --------\n",
    "            f : function that takes a pandas.DataFrame and outputs a 2d np.array.\n",
    "            features : list of features in the pd.DataFrame for which we are to \n",
    "                differentiate f.\n",
    "            labels : list of features in the np.array.\n",
    "        \"\"\"\n",
    "        self.f = f\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.h = h\n",
    "        \n",
    "    def gradient(self, X_val, feature):\n",
    "        \"\"\"\n",
    "            Numerical Gradient Calculation by way of a CFD method.\n",
    "            Inputs\n",
    "            --------\n",
    "            X_val : pandas.DataFrame with columns: features and values at\n",
    "                which we want to take the numerical gradient.\n",
    "            feature : feature by which we want to differentiate.\n",
    "        \"\"\"\n",
    "        X_prime_plus = X_val.copy()\n",
    "        X_prime_plus.loc[:,(feature)] = X_prime_plus[feature] + self.h\n",
    "        X_prime_minus = X_val.copy()\n",
    "        X_prime_minus.loc[:,(feature)] = X_prime_minus[feature] - self.h\n",
    "        \n",
    "        grad = (self.f(X_prime_plus) - self.f(X_prime_minus))/(2*self.h)\n",
    "        \n",
    "        return grad\n",
    "    def feature_att(self, X):\n",
    "        \"\"\"\n",
    "            Calculates the Gradients for all Entries in X, for each\n",
    "            feature and label combination.\n",
    "            \n",
    "            Inputs\n",
    "            --------\n",
    "            X : pandas.DataFrame with columns:features and values at\n",
    "                which we want to differentiate.\n",
    "            Returns\n",
    "            --------\n",
    "            self.__atts : [np.array[...],np.array[...]] of gradients at\n",
    "                each of the input points. Calculated for each label and stacked.\n",
    "        \"\"\"\n",
    "        first_run = True\n",
    "        for i,__label in enumerate(self.labels):\n",
    "            grads = self.gradient(X, self.features[0])[:,i]\n",
    "            for __feat in self.features[1:]:\n",
    "                grads = np.vstack((grads,self.gradient(X, __feat)[:,i]))\n",
    "            normalised_grads = np.abs(grads)/np.sum(np.abs(grads),axis=0)\n",
    "            if first_run:\n",
    "                self.__atts = grads.transpose()\n",
    "                self.__normalised = normalised_grads.transpose()\n",
    "                first_run = False\n",
    "            else:\n",
    "                self.__atts = [self.__atts, grads.transpose()]\n",
    "                self.__normalised = [self.__normalised, normalised_grads.transpose()]\n",
    "                        \n",
    "        return self.__atts#, self.__normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c3f2120",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bootstrapper():\n",
    "    def __init__(self, model, data, features, labels, suffix, explainer_type, num_straps = 50, back_size = 100):\n",
    "        self.explainer_type = explainer_type\n",
    "        self.model = model\n",
    "        self.data = data\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.num_straps = num_straps\n",
    "        self.back_size = back_size\n",
    "        self.suffix = suffix\n",
    "        \n",
    "    def bootstrap(self, X):\n",
    "        self.values = np.empty((self.num_straps, len(self.labels), len(self.features)))\n",
    "        self.mean_std_arr = np.empty((2, len(self.labels), len(self.features)))\n",
    "        for i in range(self.num_straps):\n",
    "            background_i = shap.sample(self.data, self.back_size, random_state = np.random.randint(100))\n",
    "            if self.explainer_type == 'kernel':\n",
    "                exp_i = shap.KernelExplainer(self.model, background_i)\n",
    "                shapper = exp_i.shap_values(X)\n",
    "            elif self.explainer_type == 'sample':\n",
    "                exp_i = shap.SampleExplainer(self.model, background_i)\n",
    "                shapper = exp_i.shap_values(X)\n",
    "            elif self.explainer_type == 'lime':\n",
    "                exp_i = MyLime(self.model, background_i, mode=\"regression\")\n",
    "                shapper = exp_i.attributions(X)\n",
    "            self.values[i,0,:] = shapper[0]\n",
    "            self.values[i,1,:] = shapper[1]\n",
    "        for i in range(len(self.labels)):\n",
    "            for j in range(len(self.features)):\n",
    "                self.mean_std_arr[0, i, j] = np.mean(self.values[:,i,j])\n",
    "                self.mean_std_arr[1, i, j] = np.std(self.values[:,i,j])\n",
    "            \n",
    "        return self.mean_std_arr\n",
    "    \n",
    "    def to_df(self):\n",
    "        self.bootstrap_df = self.x_list.copy()\n",
    "        for k, col in enumerate([\"mean\", \"std\"]):\n",
    "            for j in range(len(self.labels)):\n",
    "                for i in range(len(self.features)):\n",
    "                    self.bootstrap_df.insert(4 + i + j*len(self.features) + k*len(self.features)*len(self.labels), \n",
    "                                             self.features[i] + \"_\" + self.labels[j] + \"_\" + col, \n",
    "                                             self.bootstrap_array[:,k,j,i])\n",
    "        if self.save:\n",
    "            self.bootstrap_df.to_csv(\"Results/\"+self.explainer_type+\"/\"+self.explainer_type+\"bootstrap_vals_\"+self.suffix+\".csv\")\n",
    "        return self.bootstrap_df\n",
    "    def calculate(self, num_samples = 10, save = True):\n",
    "        self.x_list = self.data.iloc[np.sort(np.random.choice(self.data.shape[0], num_samples, replace =False))]\n",
    "        self.bootstrap_array = np.empty((num_samples, 2, len(self.labels), len(self.features)))\n",
    "        for i in tqdm(range(self.x_list.shape[0]), desc=\"Bootstrapping…\", ascii=False, ncols=75):\n",
    "            x_val = self.x_list.iloc[i,:]\n",
    "            self.bootstrap_array[i,:,:,:] = self.bootstrap(x_val)\n",
    "        return self.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b8e8701",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLime(shap.other.LimeTabular):\n",
    "    def __init__(self, model, data, mode=\"classification\"):\n",
    "        self.model = model\n",
    "        assert mode in [\"classification\", \"regression\"]\n",
    "        self.mode = mode\n",
    "\n",
    "        if str(type(data)).endswith(\"pandas.core.frame.DataFrame'>\"):\n",
    "            data = data.values\n",
    "        self.data = data\n",
    "        self.explainer = lime.lime_tabular.LimeTabularExplainer(data, mode=mode)\n",
    "        self.out_dim = 1#self.model(data[0:1]).shape[1]\n",
    "            \n",
    "    def attributions(self, X, num_samples=500, num_features=None):\n",
    "        try:\n",
    "            num_features = X.shape[1] if num_features is None else num_features\n",
    "        except:\n",
    "            print('exception')\n",
    "            num_features = 1\n",
    "        if str(type(X)).endswith(\"pandas.core.frame.DataFrame'>\"):\n",
    "            X = X.values\n",
    "            \n",
    "        out = [np.zeros(X.shape) for j in range(len(self.model))]\n",
    "        for i in tqdm(range(X.shape[0]), desc=\"Calculating Lime…\", ascii=False, ncols=75):\n",
    "            exp1 = self.explainer.explain_instance(X[i], self.model[0], labels=range(self.out_dim), \n",
    "                                                    num_features=num_features, num_samples=num_samples)\n",
    "            exp2 = self.explainer.explain_instance(X[i], self.model[1], labels=range(self.out_dim), \n",
    "                                                    num_features=num_features, num_samples=num_samples)\n",
    "            for k, v in exp1.local_exp[1]: \n",
    "                out[0][i,k] = v\n",
    "            for k, v in exp2.local_exp[1]: \n",
    "                out[1][i,k] = v\n",
    "          \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ec7df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define and Create Model\n",
    "\"\"\"\n",
    "def MLModel():\n",
    "    opt = Adam(learning_rate=0.001, beta_1=0.7)\n",
    "    loss='mse'\n",
    "    model = Sequential([\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(32, activation='sigmoid'),\n",
    "        layers.Dense(32, activation='tanh'),\n",
    "        layers.Dense(2)            \n",
    "    ])\n",
    "    model.compile(optimizer=opt, loss=loss)\n",
    "    return model\n",
    "  \n",
    "    \n",
    "def SimpleModel():\n",
    "    opt = Adam(learning_rate=0.001, beta_1=0.7)\n",
    "    loss='mse'\n",
    "    model = Sequential([\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(2)            \n",
    "    ])\n",
    "    model.compile(optimizer=opt, loss=loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30e1dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_list = [{'alpha' : 1.0, 'beta' : 1.0, 'gamma' : 0.37, 'delta' : 0.3, 'omega' : 1.2}, \n",
    "                  {'alpha' : 1.0, 'beta' : -0.5, 'gamma' : 0.37, 'delta' : 0.3, 'omega' : 1.2},\n",
    "                  {'alpha' : 1.0, 'beta' : -0.5, 'gamma' : 0.37, 'delta' : 1.0, 'omega' : 1.2}, \n",
    "                  {'alpha' : 1.0, 'beta' : -0.5, 'gamma' : 0.5, 'delta' : 0.3, 'omega' : 1.2},\n",
    "                  {'alpha' : -1.0, 'beta' : 1.0, 'gamma' : 0.37, 'delta' : 0.3, 'omega' : 1.2},\n",
    "                  {'alpha' : -1.0, 'beta' : 1.0, 'gamma' : 0.37, 'delta' : 1.0, 'omega' : 1.2}, \n",
    "                  {'alpha' : -1.0, 'beta' : 1.0, 'gamma' : 0.5, 'delta' : 0.3, 'omega' : 1.2},\n",
    "                  {'alpha' : -1.0, 'beta' : 1.0, 'gamma' : 0.0, 'delta' : 0.3, 'omega' : 0.0},\n",
    "                  {'alpha' : -1.0, 'beta' : -1.0, 'gamma' : 0.37, 'delta' : 0.3, 'omega' : 1.2},\n",
    "                  {'alpha' : 0.0, 'beta' : 0.0, 'gamma' : 0.37, 'delta' : 0.3, 'omega' : 1.2},\n",
    "                  {'alpha' : 1.0, 'beta' : -0.5, 'gamma' : 0.37, 'delta' : 0.0, 'omega' : 1.2}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0ee8bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Data…:   1%|▏              | 990/100000 [00:30<51:01, 32.34it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-d2d7c367e6a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mduffing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mduffing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mduffing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mduffing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduffing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mduffing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-456e9671703f>\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, num_samples, samples, end_time, gridded, num_gammas)\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;31m# Do something with the current parameter combination in ``dict_``\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;31m#Generate a trajectory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0mtrajectory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolve_ivp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtermination_event\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m             \u001b[0mtraj_cutoff\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0msamples\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrajectory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mtraj_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrajectory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10.0\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraj_cutoff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\scipy\\integrate\\_ivp\\ivp.py\u001b[0m in \u001b[0;36msolve_ivp\u001b[1;34m(fun, t_span, y0, method, t_eval, dense_output, events, vectorized, args, **options)\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'finished'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\scipy\\integrate\\_ivp\\base.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\scipy\\integrate\\_ivp\\rk.py\u001b[0m in \u001b[0;36m_step_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mh_abs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m             y_new, f_new = rk_step(self.fun, t, y, self.f, h, self.A,\n\u001b[0m\u001b[0;32m    145\u001b[0m                                    self.B, self.C, self.K)\n\u001b[0;32m    146\u001b[0m             \u001b[0mscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0matol\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrtol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\scipy\\integrate\\_ivp\\rk.py\u001b[0m in \u001b[0;36mrk_step\u001b[1;34m(fun, t, y, f, h, A, B, C, K)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mdy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Define Parameter Configuration to Model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : float, linear stiffness\n",
    "    beta  : float, non linearity in the restoring force\n",
    "    gamma : float, amplitude of the periodic driving force\n",
    "    delta : float, amount of damping\n",
    "    omega : float, angular frequency of the periodic driving force\n",
    "\"\"\"   \n",
    "for dict_param in parameter_list:\n",
    "    duffing = Duffing(parameters = dict_param)\n",
    "    eom = duffing.eom\n",
    "    suffix = duffing.suffix\n",
    "\n",
    "    end_time = 100\n",
    "    duffing.generate(100000, samples = 100, end_time = end_time)\n",
    "    duffing.scale_features()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(duffing.X_df[duffing.features], duffing.X_df[duffing.labels], test_size=0.1, random_state=42)\n",
    "    \n",
    "    X = X_test\n",
    "    y = y_test\n",
    "    \n",
    "    # Create a basic model instance\n",
    "    model = MLModel()\n",
    "\n",
    "    \"\"\"\n",
    "    Train Model\n",
    "    \"\"\"\n",
    "\n",
    "    callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=25),tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15)]\n",
    "\n",
    "\n",
    "    # pipe = make_pipeline(scaler, model)\n",
    "\n",
    "    history=model.fit(X_train, y_train, steps_per_epoch=None, epochs=500, validation_split=0.2, batch_size=1024, shuffle=True, callbacks=callbacks, verbose=0)\n",
    "\n",
    "    loss = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(\"Trained model, loss: {:5.2f}%\".format(loss))\n",
    "\n",
    "    model.save(\"Models/ml_model_\"+suffix)\n",
    "    with open('/trainHistoryDict_'+suffix, 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "    def ml_x(X):\n",
    "        return model.predict(X)[:,0]\n",
    "    def ml_v(X):\n",
    "        return model.predict(X)[:,1]\n",
    "    \n",
    "    # Make Simple ML Model\n",
    "    simple_model = SimpleModel()\n",
    "\n",
    "    \"\"\"\n",
    "    Train Model\n",
    "    \"\"\"\n",
    "    # pipe = make_pipeline(scaler, model)\n",
    "\n",
    "    history_simple=simple_model.fit(X_train, y_train, steps_per_epoch=None, epochs=500, validation_split=0.2, batch_size=1024, shuffle=True, callbacks=callbacks, verbose=0)\n",
    "    with open('/trainHistoryDict_simple_'+suffix, 'wb') as file_pi:\n",
    "        pickle.dump(history_simple.history, file_pi)\n",
    "    loss = simple_model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(\"Trained model, loss: {:5.2f}%\".format(loss))\n",
    "\n",
    "    simple_model.save(\"Models/simple_ml_model_\"+suffix)\n",
    "    \n",
    "    def simple_ml_x(X):\n",
    "        return simple_model.predict(X)[:,0]\n",
    "    def simple_ml_v(X):\n",
    "        return simple_model.predict(X)[:,1]\n",
    "\n",
    "    explainers = [\"kernel\", \"sampling\", \"lime\", \"numeric\"]\n",
    "    true_lime = [duffing.predict_x, duffing.predict_v]\n",
    "    ml_lime = [ml_x, ml_v]\n",
    "    simple_lime = [simple_ml_x, simple_ml_v]\n",
    "    models = {\"true\" : duffing.predict, \"ml\" : model.predict, \"simple\" : simple_model.predict}\n",
    "    lime_models = {\"true\" : true_lime, \"ml\" : ml_lime, \"simple\" : simple_lime}\n",
    "\n",
    "    background = shap.sample(X_test, 100)\n",
    "    choice = X.iloc[np.sort(np.random.choice(X_test.shape[0], 100, replace =False))]\n",
    "\n",
    "\n",
    "    big_df = pd.DataFrame()\n",
    "    for model_ in models:\n",
    "        for explainer in explainers:\n",
    "            print(explainer + model_)\n",
    "            if explainer == \"kernel\":\n",
    "                temp_explainer = shap.KernelExplainer(models[model_], background)\n",
    "                temp_vals = temp_explainer.shap_values(choice)\n",
    "            elif explainer == \"sampling\":\n",
    "                temp_explainer = shap.SamplingExplainer(models[model_], background)\n",
    "                temp_vals = temp_explainer.shap_values(choice)\n",
    "            elif explainer == \"lime\":\n",
    "                temp_explainer = MyLime(lime_models[model_], choice, mode='regression')\n",
    "                temp_vals = temp_explainer.attributions(choice)\n",
    "            elif explainer == \"numeric\":\n",
    "                temp_explainer = NumericExplainer(models[model_], duffing.features, duffing.labels, h = 0.001)\n",
    "                temp_vals = temp_explainer.feature_att(choice)\n",
    "            else:\n",
    "                print(\"not a valid explainer type\")\n",
    "            big_df = big_df.append(duffing.vals_to_df(temp_vals, \n",
    "                                                            choice, save=False, explainer = explainer, suffix = suffix))\n",
    "\n",
    "        \n",
    "    big_df.to_csv(\"Results/explainer_dataframe_\"+suffix+\".csv\")  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf177cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
