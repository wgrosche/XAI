{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0d653d1",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "\n",
    "Notebook dedicated to plotting the results of the explainer calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96dd020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.integrate import odeint, solve_ivp\n",
    "from scipy.fft import fft\n",
    "\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import mpl_interactions.ipyplot as iplt\n",
    "sns.set_theme(context='notebook', style='darkgrid', palette='deep', font='sans-serif', font_scale=1, color_codes=True, rc=None)\n",
    "\n",
    "# Machine Learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow import keras\n",
    "\n",
    "import shap as shap\n",
    "try:\n",
    "    import lime\n",
    "    import lime.lime_tabular    \n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Enable Jupyter Notebook's intellisense\n",
    "%config IPCompleter.greedy=True\n",
    "%matplotlib inline\n",
    "\n",
    "%matplotlib notebook\n",
    "from ipywidgets import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for reproducibility of this notebook:\n",
    "rng = np.random.RandomState(42)\n",
    "#tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "#matplotlib.use('TkAgg')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319f045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose parameter configuration\n",
    "\n",
    "alpha = 1.0\n",
    "beta = -1.0\n",
    "gamma = 0.37\n",
    "delta = 0.3\n",
    "omega = 1.2\n",
    "\n",
    "parameters = {'alpha': alpha, 'beta': beta, 'gamma': gamma, 'delta': delta, 'omega':omega}\n",
    "\n",
    "suffix = \"params_\"+str(parameters['alpha'])+\"_\"+str(parameters['beta'])+\"_\"+str(parameters['gamma'])+\"_\"+str(parameters['delta'])+\"_\"+str(parameters['omega'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feeef47b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Results/explainer_dataframe_params_1.0_-1.0_0.37_0.3_1.2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5e9aaaf5194e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load plotting data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Results/explainer_dataframe_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\XAI\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    699\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    702\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Results/explainer_dataframe_params_1.0_-1.0_0.37_0.3_1.2.csv'"
     ]
    }
   ],
   "source": [
    "# load plotting data\n",
    "\n",
    "data_df = pd.read_csv(\"Results/explainer_dataframe_\"+suffix+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "760336ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff0735b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pickle.load(open('/trainHistoryDict', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45379840",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d9871c2f6174>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/trainHistoryDict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile_pi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_pi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "with open('/trainHistoryDict', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a83472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neural network\n",
    "\n",
    "model = tf.keras.models.load_model(\"Models/ml_model_\"+suffix)\n",
    "history = model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b610a851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate NN performance\n",
    "\n",
    "\"\"\"\n",
    "Evaluate Model\n",
    "\"\"\"\n",
    "\n",
    "# evaluate the fitting validation and training losses\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "## Make Prdictions on the Test Dataset\n",
    "y_pred = pd.DataFrame(model.predict(X_test), columns=['xt','vt'])\n",
    "\n",
    "pred_norm = np.linalg.norm(y_pred[['xt','vt']].values,axis=1)\n",
    "true_norm = np.linalg.norm(y_test[['xt','vt']].values,axis=1)\n",
    "hist_data = np.abs(pred_norm-true_norm)/np.abs(true_norm)\n",
    "hist_data = pd.DataFrame(hist_data, columns=['norm'])\n",
    "\n",
    "def Remove_Outlier_Indices(df):\n",
    "    Q1 = df.quantile(0.00)\n",
    "    Q3 = df.quantile(0.95)\n",
    "    IQR = Q3 - Q1\n",
    "    trueList = ~((df > (Q3 + 1.5 * IQR)))\n",
    "    #trueList = ~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR)))\n",
    "    return trueList\n",
    "\n",
    "indices = Remove_Outlier_Indices(hist_data)\n",
    "hist_data = hist_data[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85145042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy\n",
    "f, axs = plt.subplots(1, 1, figsize=(4, 4), gridspec_kw=dict(width_ratios=[4]))\n",
    "\n",
    "sns.lineplot(data = history.history, x = epochs, y='loss',ax=axs, label='loss')\n",
    "sns.lineplot(data = history.history, x = epochs, y='val_loss',ax=axs, label='val_loss')\n",
    "\n",
    "axs.set_xlabel('Epochs')\n",
    "axs.set_ylabel('Loss')\n",
    "axs.set_title(\"Losses by Epoch\")\n",
    "axs.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35d31b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Error\n",
    "\n",
    "f, axs = plt.subplots(1, 1, figsize=(4, 4), gridspec_kw=dict(width_ratios=[4]))\n",
    "\n",
    "# Error Plot for ML Predictions\n",
    "sns.histplot(data=hist_data, x = 'norm', kde=False, stat='probability', binwidth=0.01, ax=axs)\n",
    "\n",
    "axs.set(xlim=(0, 0.6), ylim=(0, 0.4))\n",
    "axs.set_xlabel('Error')\n",
    "axs.set_ylabel('Probability')\n",
    "axs.set_title(r\"Error Plot $(\\frac{||y_{pred}-y_{true}||}{||y_{true}||})$\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe3b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bf5d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Plot ML Model\n",
    "f, axs = plt.subplots(2, 1, figsize=(8, 4), gridspec_kw=dict(width_ratios=[4, 4]))\n",
    "\n",
    "\n",
    "# True Values Plot\n",
    "sns.scatterplot(data = y_test.iloc[:,:], x = 'xt', y='vt',ax=axs[0],label='true_values', marker='x', linewidth = 1)\n",
    "\n",
    "axs[1,0].set(xlim=(-2, 2), ylim=(-2, 2))\n",
    "axs[1,0].set_xlabel('x [ ]')\n",
    "axs[1,0].set_ylabel('v [ ]')\n",
    "axs[1,0].set_title(\"Phase Space Plot (True Model)\")\n",
    "\n",
    "# ML Values Plot\n",
    "sns.scatterplot(data = y_pred.iloc[:2000,:], x='xt', y='vt',ax=axs[1],label='pred_values',  marker='x', linewidth = 1)\n",
    "\n",
    "axs[1,1].set(xlim=(-2, 2), ylim=(-2, 2))\n",
    "axs[1,1].set_xlabel('x [ ]')\n",
    "axs[1,1].set_ylabel('v [ ]')\n",
    "axs[1,1].set_title(\"Phase Space Plot (ML Model)\")\n",
    "\n",
    "f.tight_layout()\n",
    "\n",
    "f.savefig(\"Images/model_summary\"+suffix+\".svg\", dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96836a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual feature attributions\n",
    "\n",
    "# Individual Feature Contributions\n",
    "f, axs = plt.subplots(2, 4, figsize = (16,8), gridspec_kw = dict(width_ratios = [4,4,4,4]))\n",
    "\n",
    "sns.scatterplot(x='x0', y=\"xt_x0\", data=big_df, ax=axs[0,0], marker = 'x', linewidth = 1, hue = \"explainer\")\n",
    "\n",
    "axs[0,0].set_title(r\"$x_0$\")\n",
    "axs[0,0].set_xlabel('Index [ ]')\n",
    "axs[0,0].set_ylabel('Feature Contribution [ ]')\n",
    "\n",
    "sns.scatterplot(x='v0', y=\"xt_v0\", data=big_df, ax=axs[1,0], marker = 'x', linewidth = 1, hue = \"explainer\")\n",
    "axs[1,0].set_title(r\"$v_0$\")\n",
    "axs[1,0].set_xlabel('Index [ ]')\n",
    "axs[1,0].set_ylabel('Feature Contribution [ ]')\n",
    "\n",
    "sns.scatterplot(x='t', y=\"xt_t\", data=big_df, ax=axs[0,1], marker = 'x', linewidth = 1, hue = \"explainer\")\n",
    "axs[0,1].set_title(r\"$t$\")\n",
    "axs[0,1].set_xlabel('Index [ ]')\n",
    "axs[0,1].set_ylabel('Feature Contribution [ ]')\n",
    "\n",
    "sns.scatterplot(x='rand', y=\"xt_rand\", data=big_df, ax=axs[1,1], marker = 'x', linewidth = 1, hue = \"explainer\")\n",
    "\n",
    "axs[1,1].set_title(r\"$rand$\")\n",
    "axs[1,1].set_xlabel('Index [ ]')\n",
    "axs[1,1].set_ylabel('Feature Contribution [ ]')\n",
    "\n",
    "\n",
    "sns.scatterplot(x='x0', y=\"vt_x0\", data=big_df, ax=axs[0,2], marker = 'x', linewidth = 1, hue = \"explainer\")\n",
    "\n",
    "axs[0,2].set_title(r\"$x_0$\")\n",
    "axs[0,2].set_xlabel('Index [ ]')\n",
    "axs[0,2].set_ylabel('Feature Contribution [ ]')\n",
    "\n",
    "sns.scatterplot(x='v0', y=\"vt_v0\", data=big_df, ax=axs[1,2], marker = 'x', linewidth = 1, hue = \"explainer\")\n",
    "axs[1,2].set_title(r\"$v_0$\")\n",
    "axs[1,2].set_xlabel('Index [ ]')\n",
    "axs[1,2].set_ylabel('Feature Contribution [ ]')\n",
    "\n",
    "sns.scatterplot(x='v0', y=\"vt_t\", data=big_df, ax=axs[0,3], marker = 'x', linewidth = 1, hue = \"explainer\")\n",
    "axs[0,3].set_title(r\"$t$\")\n",
    "axs[0,3].set_xlabel('Index [ ]')\n",
    "axs[0,3].set_ylabel('Feature Contribution [ ]')\n",
    "\n",
    "sns.scatterplot(x='rand', y=\"vt_rand\", data=big_df, ax=axs[1,3], marker = 'x', linewidth = 1, hue = \"explainer\")\n",
    "axs[1,3].set_title(r\"$rand$\")\n",
    "axs[1,3].set_xlabel('Index [ ]')\n",
    "axs[1,3].set_ylabel('Feature Contribution [ ]')\n",
    "\n",
    "\n",
    "\n",
    "f.suptitle(r\"Individual Feature Contributions to $x_t$ and $v_t$\")\n",
    "\n",
    "f.tight_layout()\n",
    "f.savefig(\"Images/feature_contributions_sorted_by_feature_\"+suffix+\".svg\", dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c06330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregated feature importance\n",
    "\n",
    "# Aggregated\n",
    "\n",
    "f, axs = plt.subplots(1, 2, figsize = (16,8), gridspec_kw = dict(width_ratios = [4,4]))\n",
    "\n",
    "\n",
    "sns.barplot(data=agg_df_2, x = 'feature', y = np.abs(agg_df_2['value']), hue = 'explainer', ax = axs[0], ci = 95, capsize=.2)\n",
    "\n",
    "axs[0].set_title(r\"Aggregate Feature Contributions\")\n",
    "axs[0].set_xlabel('Feature [ ]')\n",
    "axs[0].set_ylabel('Feature Contribution [ ]')\n",
    "\n",
    "sns.boxplot(data=agg_df_2, x = 'feature', y = 'value', ax = axs[1], hue = 'explainer')\n",
    "axs[1].set_title(r\"All Feature Contributions\")\n",
    "axs[1].set_xlabel('Feature')\n",
    "axs[1].set_ylabel('Feature Contribution [ ]')\n",
    "\n",
    "\n",
    "f.tight_layout()\n",
    "\n",
    "f.savefig(\"Images/all_aggregated_\"+suffix+\".svg\", dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e4438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical explainer convergence study\n",
    "\n",
    "# choose random point from dataset\n",
    "x_val = np.random.choice(choice, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842e7525",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLime(shap.other.LimeTabular):\n",
    "    def __init__(self, model, data, mode=\"classification\"):\n",
    "        self.model = model\n",
    "        assert mode in [\"classification\", \"regression\"]\n",
    "        self.mode = mode\n",
    "\n",
    "        if str(type(data)).endswith(\"pandas.core.frame.DataFrame'>\"):\n",
    "            data = data.values\n",
    "        self.data = data\n",
    "        self.explainer = lime.lime_tabular.LimeTabularExplainer(data, mode=mode)\n",
    "        self.out_dim = 1#self.model(data[0:1]).shape[1]\n",
    "            \n",
    "    def attributions(self, X, num_samples=500, num_features=None):\n",
    "        try:\n",
    "            num_features = X.shape[1] if num_features is None else num_features\n",
    "        except:\n",
    "            print('exception')\n",
    "            num_features = 1\n",
    "        if str(type(X)).endswith(\"pandas.core.frame.DataFrame'>\"):\n",
    "            X = X.values\n",
    "            \n",
    "        out = [np.zeros(X.shape) for j in range(len(self.model))]\n",
    "        for i in tqdm(range(X.shape[0]), desc=\"Calculating Limeâ€¦\", ascii=False, ncols=75):\n",
    "            exp1 = self.explainer.explain_instance(X[i], self.model[0], labels=range(self.out_dim), \n",
    "                                                    num_features=num_features, num_samples=num_samples)\n",
    "            exp2 = self.explainer.explain_instance(X[i], self.model[1], labels=range(self.out_dim), \n",
    "                                                    num_features=num_features, num_samples=num_samples)\n",
    "            for k, v in exp1.local_exp[1]: \n",
    "                out[0][i,k] = v\n",
    "            for k, v in exp2.local_exp[1]: \n",
    "                out[1][i,k] = v\n",
    "          \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lime convergence study\n",
    "# use x_val from above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea11e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __init__(self,\n",
    "                 training_data,\n",
    "                 mode=\"classification\",\n",
    "                 training_labels=None,\n",
    "                 feature_names=None,\n",
    "                 categorical_features=None,\n",
    "                 categorical_names=None,\n",
    "                 kernel_width=None,\n",
    "                 kernel=None,\n",
    "                 verbose=False,\n",
    "                 class_names=None,\n",
    "                 feature_selection='auto',\n",
    "                 discretize_continuous=True,\n",
    "                 discretizer='quartile',\n",
    "                 sample_around_instance=False,\n",
    "                 random_state=None,\n",
    "                 training_data_stats=None):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d881da9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
