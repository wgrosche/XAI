{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ef288a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.integrate import odeint, solve_ivp\n",
    "from scipy.fft import fft\n",
    "\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import mpl_interactions.ipyplot as iplt\n",
    "sns.set_theme(context='notebook', style='darkgrid', palette='deep', font='sans-serif', font_scale=1, color_codes=True, rc=None)\n",
    "\n",
    "# Machine Learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow import keras\n",
    "\n",
    "import shap as shap\n",
    "try:\n",
    "    import lime\n",
    "    import lime.lime_tabular    \n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Enable Jupyter Notebook's intellisense\n",
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "from ipywidgets import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for reproducibility of this notebook:\n",
    "rng = np.random.RandomState(42)\n",
    "#tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac801ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Duffing():\n",
    "    \"\"\"\n",
    "        Class for the Duffing Oscillator\n",
    "    \"\"\"\n",
    "    def __init__(self, parameters = {'alpha': 0.3, 'beta': -0.1, 'gamma': 0.37, 'delta': 0.3, 'omega': 1.2}, labels = ['xt','vt'], features = ['x0','v0','t','rand'], scaler = None):\n",
    "        \"\"\"\n",
    "            Define Parameter Configuration to Model\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            alpha : float, linear stiffness\n",
    "            beta  : float, non linearity in the restoring force\n",
    "            gamma : float, amplitude of the periodic driving force\n",
    "            delta : float, amount of damping\n",
    "            omega : float, angular frequency of the periodic driving force\n",
    "        \"\"\"   \n",
    "        self.parameters = parameters\n",
    "        self.labels = labels\n",
    "        self.features = features\n",
    "        self.scaler = scaler\n",
    "        self.suffix = \"params_\"+str(parameters['alpha'])+\"_\"+str(parameters['beta'])+\"_\"+str(parameters['gamma'])+\"_\"+str(parameters['delta'])+\"_\"+str(parameters['omega'])\n",
    "\n",
    "    def eom(self, t, u):\n",
    "        \"\"\"\n",
    "            Duffing Oscillator Equation of Motion\n",
    "\n",
    "            ddx + delta * dx + alpha * x + beta * x**3 = gamma * cos(omega * t)\n",
    "\n",
    "            Input\n",
    "            ----------\n",
    "            u : vector of length 2, (x,v)\n",
    "                Position and Velocity at time t\n",
    "            t : float, the time t\n",
    "\n",
    "            Returns\n",
    "            ----------\n",
    "            [dx,ddx] : Tuple, Time derivatives of \n",
    "                        position and velocity at time t\n",
    "        \"\"\"\n",
    "        x, dx = u[0], u[1]\n",
    "        ddx = (self.parameters['gamma'] * np.cos(self.parameters['omega'] * t) - (self.parameters['delta'] * dx + self.parameters['alpha'] * x + self.parameters['beta'] * x**3))\n",
    "\n",
    "        return [dx,ddx]\n",
    "\n",
    "    def termination_event(self, t, y):\n",
    "        \"\"\"\n",
    "            Stops Numerical Integration once points wander too far away\n",
    "        \"\"\"\n",
    "        return (np.abs(y[0]) - 10)*(np.abs(y[1]) - 10)\n",
    "    termination_event.terminal = True\n",
    "\n",
    "\n",
    "    def generate(self, num_samples = int(5e1), samples=10, end_time=100, gridded=False):\n",
    "        \"\"\"\n",
    "            Generates training samples using scipy.integrate.odeint\n",
    "            to calculate the temporal evolution of a Duffing system.\n",
    "    \n",
    "            Samples randomly from x0 in [-2,2], v0 in [-1,1].\n",
    "    \n",
    "            For each set of initial conditions we generate a trajectory.\n",
    "            The trajectory is randomly sampled to generate training\n",
    "            pairs: X = (x0,v0,t), y = (xt,vt)\n",
    "    \n",
    "            Input\n",
    "            ----------\n",
    "            num_samples : int, number of training\n",
    "                            samples to be generated\n",
    "    \n",
    "            Returns\n",
    "            ----------\n",
    "            X : array((num_samples,3)), each entry in the array\n",
    "                is a training sample (x0,v0,t)\n",
    "            y : array((num_samples,2)), each entry in the array\n",
    "                is a target sample (xt,vt)\n",
    "        \"\"\"\n",
    "            \n",
    "        #Define bounds of the sampling\n",
    "        x_min = -2\n",
    "        x_max = 2\n",
    "        v_min = -2\n",
    "        v_max = 2\n",
    "        #Initialise the output arrays        \n",
    "        X = np.empty((num_samples*(samples), len(np.hstack((self.features, self.labels)))))\n",
    "        #Define the t_range to draw from\n",
    "        t_range = np.linspace(0, end_time, 100, endpoint=False)\n",
    "        t_vals = np.sort(np.random.choice(t_range, size = samples, replace=False))\n",
    "        if gridded:\n",
    "            x_range = np.linspace(x_min, x_max, int(np.sqrt(num_samples)), endpoint = True)\n",
    "            v_range = np.linspace(v_min, v_max, int(np.sqrt(num_samples)), endpoint = True)\n",
    "            #Generate num_samples samples\n",
    "            for i, x0 in tqdm(enumerate(x_range), desc=\"Generating Data…\", ascii=False, ncols=75):\n",
    "                for v0 in v_range:\n",
    "                    #Generate a trajectory\n",
    "                    trajectory = solve_ivp(self.eom, [0, end_time], [x0,v0], t_eval = t_vals, events = [self.termination_event])\n",
    "                    traj_cutoff =  samples - len(trajectory.y[0])\n",
    "                    if traj_cutoff > 0:\n",
    "                        trajectory.y[0] = np.append(trajectory.y[0].reshape(-1,1), 10.0*np.ones(traj_cutoff))\n",
    "                        trajectory.y[1] = np.append(trajectory.y[1].reshape(-1,1), 10.0*np.ones(traj_cutoff))\n",
    "                    X[i*samples:(i+1)*samples,:] = np.hstack((x0*np.ones(samples).reshape(-1,1), \n",
    "                                                        v0*np.ones(samples).reshape(-1,1), \n",
    "                                                        t_vals.reshape(-1,1), \n",
    "                                                        np.random.uniform(-1,1,samples).reshape(-1,1),\n",
    "                                                        trajectory.y[0].reshape(-1,1), \n",
    "                                                        trajectory.y[1].reshape(-1,1)))\n",
    "\n",
    "        else:\n",
    "            #Generate num_samples samples\n",
    "            for i in tqdm(range(num_samples), desc=\"Generating Data…\", ascii=False, ncols=75):\n",
    "                #Generate random starting positions\n",
    "                x0 = (x_max - x_min) * np.random.random_sample() + x_min\n",
    "                v0 = (v_max - v_min) * np.random.random_sample() + v_min \n",
    "                #Generate a trajectory\n",
    "                trajectory = solve_ivp(self.eom, [0, end_time], [x0,v0], t_eval = t_vals, events = [self.termination_event])\n",
    "                traj_cutoff =  samples - len(trajectory.y[0])\n",
    "                if traj_cutoff > 0:\n",
    "                    x_traj = np.vstack((trajectory.y[0].reshape(-1,1), 10.0*np.ones(traj_cutoff).reshape(-1,1)))\n",
    "                    v_traj = np.vstack((trajectory.y[1].reshape(-1,1), 10.0*np.ones(traj_cutoff).reshape(-1,1)))\n",
    "                    X[i*samples:(i+1)*samples,:] = np.hstack((x0*np.ones(samples).reshape(-1,1), \n",
    "                                                            v0*np.ones(samples).reshape(-1,1), \n",
    "                                                            t_vals.reshape(-1,1), \n",
    "                                                            np.random.uniform(-1,1,samples).reshape(-1,1),\n",
    "                                                            x_traj, \n",
    "                                                            v_traj))\n",
    "                else:\n",
    "                    X[i*samples:(i+1)*samples,:] = np.hstack((x0*np.ones(samples).reshape(-1,1), \n",
    "                                                            v0*np.ones(samples).reshape(-1,1), \n",
    "                                                            t_vals.reshape(-1,1), \n",
    "                                                            np.random.uniform(-1,1,samples).reshape(-1,1),\n",
    "                                                            trajectory.y[0].reshape(-1,1), \n",
    "                                                            trajectory.y[1].reshape(-1,1)))\n",
    "        \n",
    "        self.X_df = pd.DataFrame(X, columns = np.hstack((self.features, self.labels)))\n",
    "        return self.X_df\n",
    "\n",
    "    def scale_features(self):\n",
    "        if self.scaler == None:\n",
    "            self.scaler = MinMaxScaler(feature_range=[0,1])\n",
    "            self.X_df[self.features] = self.scaler.fit_transform(self.X_df[self.features].values)\n",
    "        else: return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a65d591",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define Parameter Configuration to Model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : float, linear stiffness\n",
    "    beta  : float, non linearity in the restoring force\n",
    "    gamma : float, amplitude of the periodic driving force\n",
    "    delta : float, amount of damping\n",
    "    omega : float, angular frequency of the periodic driving force\n",
    "\"\"\"   \n",
    "alpha = -1.0\n",
    "beta = 1.0\n",
    "gamma = 0.37\n",
    "delta = 1.0\n",
    "omega = 1.2\n",
    "\n",
    "parameters_now = {'alpha': alpha, 'beta': beta, 'gamma': gamma, 'delta': delta, 'omega':omega}\n",
    "duffing = Duffing(parameters = parameters_now)\n",
    "eom = duffing.eom\n",
    "suffix = duffing.suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b199a9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Data…: 100%|████████████| 100000/100000 [50:56<00:00, 32.72it/s]\n"
     ]
    }
   ],
   "source": [
    "end_time = 100\n",
    "duffing.generate(100000, samples = 100, end_time = end_time)\n",
    "duffing.scale_features()\n",
    "X = duffing.X_df[duffing.features]\n",
    "y = duffing.X_df[duffing.labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f508be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dacb69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define and Create Model\n",
    "\"\"\"\n",
    "\n",
    "def MLModel():\n",
    "    opt = Adam(learning_rate=0.001, beta_1=0.7)\n",
    "    loss='mse'\n",
    "    model = Sequential([\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(32, activation='sigmoid'),\n",
    "        layers.Dense(32, activation='tanh'),\n",
    "        layers.Dense(2)            \n",
    "    ])\n",
    "    model.compile(optimizer=opt, loss=loss)\n",
    "    return model\n",
    "\n",
    "# Create a basic model instance\n",
    "model = MLModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f909935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "7032/7032 [==============================] - 56s 8ms/step - loss: 0.0762 - val_loss: 0.0690\n",
      "Epoch 2/500\n",
      "7032/7032 [==============================] - 55s 8ms/step - loss: 0.0572 - val_loss: 0.0567\n",
      "Epoch 3/500\n",
      "7032/7032 [==============================] - 56s 8ms/step - loss: 0.0502 - val_loss: 0.0459\n",
      "Epoch 4/500\n",
      "7032/7032 [==============================] - 57s 8ms/step - loss: 0.0454 - val_loss: 0.0535\n",
      "Epoch 5/500\n",
      "7032/7032 [==============================] - 59s 8ms/step - loss: 0.0390 - val_loss: 0.0332\n",
      "Epoch 6/500\n",
      "7032/7032 [==============================] - 57s 8ms/step - loss: 0.0328 - val_loss: 0.0282\n",
      "Epoch 7/500\n",
      "7032/7032 [==============================] - 55s 8ms/step - loss: 0.0269 - val_loss: 0.0327\n",
      "Epoch 8/500\n",
      "7032/7032 [==============================] - 57s 8ms/step - loss: 0.0205 - val_loss: 0.0130\n",
      "Epoch 9/500\n",
      "7032/7032 [==============================] - 55s 8ms/step - loss: 0.0142 - val_loss: 0.0084\n",
      "Epoch 10/500\n",
      "7032/7032 [==============================] - 55s 8ms/step - loss: 0.0123 - val_loss: 0.0085\n",
      "Epoch 11/500\n",
      "7032/7032 [==============================] - 55s 8ms/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 12/500\n",
      "7032/7032 [==============================] - 55s 8ms/step - loss: 0.0109 - val_loss: 0.0138\n",
      "Epoch 13/500\n",
      "7032/7032 [==============================] - 54s 8ms/step - loss: 0.0103 - val_loss: 0.0134\n",
      "Epoch 14/500\n",
      "7032/7032 [==============================] - 54s 8ms/step - loss: 0.0105 - val_loss: 0.0155\n",
      "Epoch 15/500\n",
      "7032/7032 [==============================] - 54s 8ms/step - loss: 0.0100 - val_loss: 0.0188\n",
      "Epoch 16/500\n",
      "7032/7032 [==============================] - 53s 8ms/step - loss: 0.0102 - val_loss: 0.0077\n",
      "Epoch 17/500\n",
      "7032/7032 [==============================] - 54s 8ms/step - loss: 0.0106 - val_loss: 0.0057\n",
      "Epoch 18/500\n",
      "7032/7032 [==============================] - 54s 8ms/step - loss: 0.0099 - val_loss: 0.0070\n",
      "Epoch 19/500\n",
      "7032/7032 [==============================] - 54s 8ms/step - loss: 0.0102 - val_loss: 0.0206\n",
      "Epoch 20/500\n",
      "7032/7032 [==============================] - 54s 8ms/step - loss: 0.0100 - val_loss: 0.0098\n",
      "Epoch 21/500\n",
      "7032/7032 [==============================] - 54s 8ms/step - loss: 0.0103 - val_loss: 0.0134\n",
      "Epoch 22/500\n",
      "7032/7032 [==============================] - 54s 8ms/step - loss: 0.0108 - val_loss: 0.0120\n",
      "Epoch 23/500\n",
      "7032/7032 [==============================] - 54s 8ms/step - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 24/500\n",
      "7032/7032 [==============================] - 54s 8ms/step - loss: 0.0102 - val_loss: 0.0126\n",
      "Epoch 25/500\n",
      "7032/7032 [==============================] - 55s 8ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 26/500\n",
      "7032/7032 [==============================] - 53s 8ms/step - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 27/500\n",
      "7032/7032 [==============================] - 53s 8ms/step - loss: 0.0106 - val_loss: 0.0123\n",
      "Epoch 28/500\n",
      "7032/7032 [==============================] - 53s 8ms/step - loss: 0.0098 - val_loss: 0.0060\n",
      "Epoch 29/500\n",
      "6700/7032 [===========================>..] - ETA: 2s - loss: 0.0094"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train Model\n",
    "\"\"\"\n",
    "#model.build()\n",
    "# Display the model's architecture\n",
    "#model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=25),\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='loss', patience=25)]\n",
    "\n",
    "\n",
    "# pipe = make_pipeline(scaler, model)\n",
    "\n",
    "history=model.fit(X_train, y_train, steps_per_epoch=None, epochs=500, \n",
    "                  validation_split=0.2, batch_size=1024, shuffle=True, callbacks=callbacks, verbose=1)\n",
    "\n",
    "loss = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Trained model, loss: {:5.2f}%\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7c7971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate Model\n",
    "\"\"\"\n",
    "\n",
    "# evaluate the fitting validation and training losses\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "## Make Prdictions on the Test Dataset\n",
    "y_pred = pd.DataFrame(model.predict(X_test), columns=['xt','vt'])\n",
    "\n",
    "pred_norm = np.linalg.norm(y_pred[['xt','vt']].values,axis=1)\n",
    "true_norm = np.linalg.norm(y_test[['xt','vt']].values,axis=1)\n",
    "hist_data = np.abs(pred_norm-true_norm)/np.abs(true_norm)\n",
    "hist_data = pd.DataFrame(hist_data, columns=['norm'])\n",
    "\n",
    "def Remove_Outlier_Indices(df):\n",
    "    Q1 = df.quantile(0.00)\n",
    "    Q3 = df.quantile(0.95)\n",
    "    IQR = Q3 - Q1\n",
    "    trueList = ~((df > (Q3 + 1.5 * IQR)))\n",
    "    #trueList = ~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR)))\n",
    "    return trueList\n",
    "\n",
    "indices = Remove_Outlier_Indices(hist_data)\n",
    "hist_data = hist_data[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed848c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Plot ML Model\n",
    "f, axs = plt.subplots(2, 2, figsize=(12, 8), gridspec_kw=dict(width_ratios=[4, 4]))\n",
    "\n",
    "sns.lineplot(data = history.history, x = epochs, y='loss',ax=axs[0,0], label='loss')\n",
    "sns.lineplot(data = history.history, x = epochs, y='val_loss',ax=axs[0,0], label='val_loss')\n",
    "\n",
    "axs[0,0].set_xlabel('Epochs')\n",
    "axs[0,0].set_ylabel('Loss')\n",
    "axs[0,0].set_title(\"Losses by Epoch\")\n",
    "axs[0,0].legend()\n",
    "\n",
    "# Error Plot for ML Predictions\n",
    "sns.histplot(data=hist_data, x = 'norm', kde=False, stat='probability', binwidth=0.01, ax=axs[0,1])\n",
    "\n",
    "axs[0,1].set(xlim=(0, 0.6), ylim=(0, 0.4))\n",
    "axs[0,1].set_xlabel('Error')\n",
    "axs[0,1].set_ylabel('Probability')\n",
    "axs[0,1].set_title(r\"Error Plot $(\\frac{||y_{pred}-y_{true}||}{||y_{true}||})$\")\n",
    "\n",
    "# True Values Plot\n",
    "sns.scatterplot(data = y_test.iloc[:2000,:], x = 'xt', y='vt',ax=axs[1,0],label='true_values', marker='x', linewidth = 1)\n",
    "\n",
    "axs[1,0].set(xlim=(-2, 2), ylim=(-2, 2))\n",
    "axs[1,0].set_xlabel('x [ ]')\n",
    "axs[1,0].set_ylabel('v [ ]')\n",
    "axs[1,0].set_title(\"Phase Space Plot (True Model)\")\n",
    "\n",
    "# ML Values Plot\n",
    "sns.scatterplot(data = y_pred.iloc[:2000,:], x='xt', y='vt',ax=axs[1,1],label='pred_values',  marker='x', linewidth = 1)\n",
    "\n",
    "axs[1,1].set(xlim=(-2, 2), ylim=(-2, 2))\n",
    "axs[1,1].set_xlabel('x [ ]')\n",
    "axs[1,1].set_ylabel('v [ ]')\n",
    "axs[1,1].set_title(\"Phase Space Plot (ML Model)\")\n",
    "\n",
    "f.tight_layout()\n",
    "\n",
    "f.savefig(\"Images/model_summary\"+suffix+\".svg\", dpi='figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa57ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Models/ml_model_\"+suffix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
